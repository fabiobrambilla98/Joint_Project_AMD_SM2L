{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_df = dd.read_csv(\"../datasets/HI-Small_Trans.csv\")\n",
    "dask_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proportion Laundering and not Laundering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_laundering = (dask_df['Is Laundering'] == 0).sum().compute()\n",
    "laundering = (dask_df['Is Laundering'] == 1).sum().compute()\n",
    "print(f\"Total transactions: {not_laundering + laundering}\")\n",
    "print(f\"Not laundering transactions: {not_laundering}\")\n",
    "print(f\"Laundering transactions: {laundering}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display payment format in relation to laundering transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the number of corresponding values for each value of the \"Payment Format\" and \"Is Laundering\" columns\n",
    "count_values = dask_df.groupby(['Payment Format', 'Is Laundering']).size().compute()\n",
    "\n",
    "# Convert the results to a Pandas DataFrame and use the unstack() method\n",
    "count_values_payment = count_values.unstack()\n",
    "\n",
    "print(count_values_payment)\n",
    "\n",
    "# Create a bar chart with a logarithmic scale\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "bar_width = 0.35\n",
    "bar_positions = range(len(count_values_payment.index))\n",
    "axs[0].bar(bar_positions, count_values_payment[0], bar_width, label='Is Laundering = 0')\n",
    "axs[0].bar([p + bar_width for p in bar_positions], count_values_payment[1], bar_width, label='Is Laundering = 1')\n",
    "axs[0].set_xticks(bar_positions)\n",
    "axs[0].set_xticklabels(count_values_payment.index, rotation='vertical') \n",
    "axs[0].set_xticklabels(count_values_payment.index)\n",
    "axs[0].set_xlabel('Payment Format')\n",
    "axs[0].set_ylabel('Number of corresponding values')\n",
    "axs[0].set_title('Bar chart in arithmetic scale')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].bar(bar_positions, count_values_payment[0], bar_width, label='Is Laundering = 0')\n",
    "axs[1].bar([p + bar_width for p in bar_positions], count_values_payment[1], bar_width, label='Is Laundering = 1')\n",
    "axs[1].set_xticks(bar_positions)\n",
    "axs[1].set_xticklabels(count_values_payment.index, rotation='vertical') \n",
    "axs[1].set_xticklabels(count_values_payment.index)\n",
    "axs[1].set_xlabel('Payment Format')\n",
    "axs[1].set_ylabel('Number of corresponding values')\n",
    "axs[1].set_title('Bar chart in logarithmic scale')\n",
    "axs[1].legend()\n",
    "axs[1].set_yscale('log')\n",
    "\n",
    "# Show the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display payment currency in relation to laundering transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of corresponding values for each value of the \"Payment Format\" and \"Is Laundering\" columns\n",
    "count_values = dask_df.groupby(['Payment Currency', 'Is Laundering']).size().compute()\n",
    "\n",
    "# Convert the results to a Pandas DataFrame and use the unstack() method\n",
    "count_values = count_values.unstack()\n",
    "\n",
    "print(count_values.sort_values(1, ascending=False))\n",
    "\n",
    "# Create a bar chart with a logarithmic scale\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "bar_width = 0.35\n",
    "bar_positions = range(len(count_values.index))\n",
    "axs[0].bar(bar_positions, count_values[0], bar_width, label='Is Laundering = 0')\n",
    "axs[0].bar([p + bar_width for p in bar_positions], count_values[1], bar_width, label='Is Laundering = 1')\n",
    "axs[0].set_xticks(bar_positions)\n",
    "axs[0].set_xticklabels(count_values.index, rotation='vertical') \n",
    "axs[0].set_xticklabels(count_values.index)\n",
    "axs[0].set_xlabel('Payment Currency')\n",
    "axs[0].set_ylabel('Number of corresponding values')\n",
    "axs[0].set_title('Bar chart in arithmetic scale')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].bar(bar_positions, count_values[0], bar_width, label='Is Laundering = 0')\n",
    "axs[1].bar([p + bar_width for p in bar_positions], count_values[1], bar_width, label='Is Laundering = 1')\n",
    "axs[1].set_xticks(bar_positions)\n",
    "axs[1].set_xticklabels(count_values.index, rotation='vertical') \n",
    "axs[1].set_xticklabels(count_values.index)\n",
    "axs[1].set_xlabel('Payment Currency')\n",
    "axs[1].set_ylabel('Number of corresponding values')\n",
    "axs[1].set_title('Bar chart in logarithmic scale')\n",
    "axs[1].legend()\n",
    "axs[1].set_yscale('log')\n",
    "\n",
    "# Show the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display top 10 accounts for fraudolent transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_df = dask_df.groupby('Account')['Is Laundering'].sum().reset_index()\n",
    "account1_df = dask_df.groupby('Account.1')['Is Laundering'].sum().reset_index()\n",
    "merged_df = account_df.merge(account1_df, left_on='Account', right_on='Account.1')\n",
    "\n",
    "# somma i valori di Is Laundering\n",
    "merged_df['Is Laundering'] = merged_df['Is Laundering_x'] + merged_df['Is Laundering_y']\n",
    "\n",
    "# seleziona solo le colonne necessarie\n",
    "merged_df = merged_df[['Account', 'Is Laundering']]\n",
    "merged_df = merged_df.sort_values('Is Laundering', ascending=False)\n",
    "merged_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversione della colonna 'date' in oggetti datetime\n",
    "dask_df['Timestamp'] = dd.to_datetime(dask_df['Timestamp'], format='%Y/%m/%d %H:%M')\n",
    "# Conversione degli oggetti datetime in numeri float rappresentanti la data\n",
    "dask_df['Timestamp'] = dask_df['Timestamp'].astype('int64') / 10**9\n",
    "\n",
    "df = dask_df.compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(list(set(df['Account']).union(set(df['Account.1']))))\n",
    "df[['Account', 'Account.1']] = df[['Account', 'Account.1']].apply(le.transform)\n",
    "le.fit(list(set(df['Receiving Currency']).union(set(df['Payment Currency']))))\n",
    "df[['Receiving Currency', 'Payment Currency']] = df[['Receiving Currency', 'Payment Currency']].apply(le.transform)\n",
    "df[['Payment Format']] = df[['Payment Format']].apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display correlation matrix for fraudolent transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm_laundering = df[df['Is Laundering'] == 1].corr()\n",
    "cm_not_laundering = df[df['Is Laundering'] == 0].corr()\n",
    "\n",
    "# create subplots\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(20, 5))\n",
    "\n",
    "# plot the first correlation matrix heatmap\n",
    "sns.heatmap(cm_laundering, cmap='coolwarm', annot=False, ax=axs[0])\n",
    "axs[0].set_title('Is Laundering = 1')\n",
    "\n",
    "# plot the second correlation matrix heatmap\n",
    "sns.heatmap(cm_not_laundering, cmap='coolwarm', annot=False, ax=axs[1])\n",
    "axs[1].set_title('Is Laundering = 0')\n",
    "\n",
    "# display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Laundering:\")\n",
    "count_amount, count_currency = len(df[(df['Amount Received'] == df['Amount Paid']) & (df['Is Laundering'] == 1)]), len(df[(df['Receiving Currency'] == df['Payment Currency']) & (df['Is Laundering'] == 1)])\n",
    "print(f\"    Same amount: {count_amount}\")\n",
    "print(f\"    Same currency: {count_currency}\")\n",
    "print(f\"    Difference: {np.abs(count_amount - count_currency)}\\n\")\n",
    "\n",
    "count_amount, count_currency = len(df[(df['Amount Received'] != df['Amount Paid']) & (df['Is Laundering'] == 1)]), len(df[(df['Receiving Currency'] != df['Payment Currency']) & (df['Is Laundering'] == 1)])\n",
    "print(f\"    Different amount: {count_amount}\")\n",
    "print(f\"    Different currency: {count_currency}\")\n",
    "print(f\"    Difference: {np.abs(count_amount - count_currency)}\\n\")\n",
    "\n",
    "print(\"Not Laundering:\")\n",
    "count_amount, count_currency = len(df[(df['Amount Received'] == df['Amount Paid']) & (df['Is Laundering'] == 0)]), len(df[(df['Receiving Currency'] == df['Payment Currency']) & (df['Is Laundering'] == 0)])\n",
    "print(f\"    Same amount: {count_amount}\")\n",
    "print(f\"    Same currency: {count_currency}\")\n",
    "print(f\"    Difference: {np.abs(count_amount - count_currency)}\\n\")\n",
    "\n",
    "count_amount, count_currency = len(df[(df['Amount Received'] != df['Amount Paid']) & (df['Is Laundering'] == 0)]), len(df[(df['Receiving Currency'] != df['Payment Currency']) & (df['Is Laundering'] == 0)])\n",
    "print(f\"    Different amount: {count_amount}\")\n",
    "print(f\"    Different currency: {count_currency}\")\n",
    "print(f\"    Difference: {np.abs(count_amount - count_currency)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More correlation among Accounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find how many times an Account send laund money and not laund money to the same Account.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df[['Account', 'Account.1', 'Is Laundering']]\n",
    "df_grouped = df_temp.groupby(['Account', 'Account.1'])['Is Laundering'].nunique().reset_index()\n",
    "df_grouped[df_grouped['Is Laundering'] > 1].groupby('Account').count().reset_index().rename(columns={'Is Laundering': 'times'}).drop('Account.1', axis=1).sort_values(by='times', ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all transactions that are send from A to B with a certain value and from B to C with the same value.\n",
    "\n",
    "For this it is necessary to use something like graphframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/fabio/jars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from graphframes import GraphFrame\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark_driver_memory = \"10g\"\n",
    "spark_executor_memory = \"6g\"\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "                    .config(\"spark.driver.memory\", spark_driver_memory) \\\n",
    "                    .config(\"spark.executor.memory\", spark_executor_memory) \\\n",
    "                    .master(\"local[*]\") \\\n",
    "                    .getOrCreate()\n",
    "print(\"Spark session created\")\n",
    "sc = spark.sparkContext\n",
    "print(\"Spark context created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField('timestamp', FloatType(), True),\n",
    "    StructField('from_bank', IntegerType(), True),\n",
    "    StructField('from_account', IntegerType(), True),\n",
    "    StructField('to_bank', IntegerType(), True),\n",
    "    StructField('to_account', IntegerType(), True),\n",
    "    StructField('amount_received', FloatType(), True),\n",
    "    StructField('receiving_currency', IntegerType(), True),\n",
    "    StructField('amount_paid', FloatType(), True),\n",
    "    StructField('payment_currency', IntegerType(), True),\n",
    "    StructField('payment_format', IntegerType(), True),\n",
    "    StructField('is_laundering', IntegerType(), True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.rename(columns={'Timestamp': 'timestamp', 'From Bank': 'from_bank', 'Account': 'account1',\n",
    "                           'To Bank': 'to_bank', 'Account.1': 'account2', 'Amount Received': 'amount_received',\n",
    "                             'Receiving Currency': 'receiving_currency', 'Amount Paid': 'amount_paid', 'Payment Currency': 'payment_currency',\n",
    "                               'Payment Format': 'payment_format', 'Is Laundering': 'is_laundering'})\n",
    "df.to_parquet('df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark.read.parquet('df.parquet')\n",
    "spark_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verteces = spark_df.select(col(\"account1\").alias(\"id\")).union(spark_df.select(col(\"account2\").alias(\"id\"))).distinct()\n",
    "edges = spark_df.select(col(\"account1\").alias(\"src\"), col(\"account2\").alias(\"dst\"), col(\"amount_paid\").alias(\"amount\"), col(\"timestamp\"), col(\"payment_format\"), col(\"is_laundering\"))\n",
    "g = GraphFrame(verteces, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = g.find(\"(a)-[c1]->(b); (b)-[c2]->(c) \").filter(\"\"\"\n",
    "                                              a != b and\n",
    "                                              b != c and\n",
    "\n",
    "                                              c1.amount == c2.amount and\n",
    "                                              c1.timestamp < c2.timestamp\n",
    "                                            \"\"\")\n",
    "pattern.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_features =  np.array(pattern.select('c1','c2').collect(), dtype=int).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "dictionary = defaultdict(list)\n",
    "for array in array_features:\n",
    "    dictionary[(array[0][4], array[1][4])].append((array[0][5], array[1][5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le.fit(list(count_values_payment.reset_index()['Payment Format']))\n",
    "c = Counter()\n",
    "l = []\n",
    "matrix = [[0 for _ in range(6)] for _ in range(7)]\n",
    "data = {}\n",
    "for key, items in dictionary.items():\n",
    "    i = Counter(items)\n",
    "    string = f\"{le.inverse_transform([key[0]])[0]}-{le.inverse_transform([key[1]])[0]}\"\n",
    "    data[string] = np.array([[i[(0,0)], i[(0,1)]], [i[(1,0)], i[(1,1)]]])\n",
    "\n",
    "fig, axs = plt.subplots(2, 6, figsize=(15, 5))\n",
    "\n",
    "# Loop over each payment type and display the matrix values in the corresponding subplot\n",
    "for i, (payment, matrix) in enumerate(data.items()):\n",
    "    # Compute the row and column indices for the current subplot\n",
    "    row = i // 6\n",
    "    col = i % 6\n",
    "    \n",
    "    # Display the matrix values in the current subplot\n",
    "    axs[row, col].imshow(matrix, cmap='Greens')\n",
    "    axs[row, col].set_xticks([0, 1])\n",
    "    axs[row, col].set_yticks([0, 1])\n",
    "    axs[row, col].set_xticklabels(['0', '1'])\n",
    "    axs[row, col].set_yticklabels(['0', '1'])\n",
    "    axs[row, col].set_xlabel(str(payment.split(\"-\")[1]))\n",
    "    axs[row, col].set_ylabel(str(payment.split(\"-\")[0]))\n",
    "    axs[row, col].xaxis.set_label_position('top')\n",
    "    axs[row, col].yaxis.set_label_position('left')\n",
    "    axs[row, col].xaxis.set_ticks_position('top')\n",
    "    axs[row, col].yaxis.set_ticks_position('left')\n",
    "\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            axs[row, col].annotate(str(matrix[i, j]), xy=(j, i), ha='center', va='center', color='grey')\n",
    "\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.subplots_adjust(wspace=0.8, hspace=0.5)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = g.find(\"(a)-[c1]->(b); (c)-[c2]->(b); (d)-[c3]->(b); (b)-[c4]->(e) \")\\\n",
    ".filter(\"\"\" \n",
    "        a != b and\n",
    "        c != a and\n",
    "        d != c and\n",
    "        b != e and\n",
    "\n",
    "        (c1.amount + c2.amount + c3.amount) == c4.amount\n",
    "\"\"\")\n",
    "pattern.show(5, truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
