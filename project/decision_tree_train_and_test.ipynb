{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from collections import Counter\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create tree classifier from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class DTC():\n",
    "    def __init__(self, random_state = None, max_depth = None, min_sample_split = 2, criterion = \"gini\", min_info_gain = 0, max_features = None, max_thresholds = None, class_weights = {}):\n",
    "        \"\"\"\n",
    "        Initializes the Decision Tree Classifier.\n",
    "\n",
    "        Parameters:\n",
    "        - random_state: int or None, optional (default=None)\n",
    "            Seed for the random number generator.\n",
    "        - max_depth: int or None, optional (default=None)\n",
    "            The maximum depth of the decision tree. If None, the tree is grown until all leaves are pure or until all leaves contain less than min_sample_split samples.\n",
    "        - min_sample_split: int, optional (default=2)\n",
    "            The minimum number of samples required to split an internal node.\n",
    "        - criterion: str, optional (default=\"gini\")\n",
    "            The function to measure the quality of a split. Supported criteria are \"gini\" for the Gini impurity, \"entropy\" for the information gain, and \"shannon\" for the Shannon entropy.\n",
    "        - min_info_gain: float, optional (default=0)\n",
    "            The minimum information gain required to split an internal node.\n",
    "        - max_features: int, float, \"sqrt\", \"log2\", or None, optional (default=None)\n",
    "            The number of features to consider when looking for the best split. If int, then consider max_features features at each split. If float, then max_features is a fraction and int(max_features * n_features) features are considered. If \"sqrt\", then max_features=sqrt(n_features). If \"log2\", then max_features=log2(n_features). If None, then all features are considered.\n",
    "        - max_thresholds: int or None, optional (default=None)\n",
    "            The maximum number of thresholds to consider for each feature when looking for the best split. If None, all unique feature values are considered as potential thresholds.\n",
    "        - class_weights: dict, optional (default={})\n",
    "            Weights associated with classes. If provided, the class probabilities are multiplied by the corresponding weight.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        \n",
    "        self.max_depth = max_depth\n",
    "        self.min_sample_split = min_sample_split\n",
    "        self.criterion = criterion\n",
    "        self.min_info_gain = min_info_gain\n",
    "        self.max_features = max_features\n",
    "        self.max_thresholds = max_thresholds\n",
    "        self.class_weights = class_weights\n",
    "        self.tree = None\n",
    "        self.random_state = random_state\n",
    "        np.random.seed(self.random_state)\n",
    "        self.node_counter = 0\n",
    "        self.features_gain_dict = defaultdict(float)\n",
    "        \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fits the decision tree classifier to the training data.\n",
    "\n",
    "        Parameters:\n",
    "        - X: array-like of shape (n_samples, n_features)\n",
    "            The training input samples.\n",
    "        - y: array-like of shape (n_samples,)\n",
    "            The target values.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        self.node_counter = 0\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = np.array(X)\n",
    "        if isinstance(y, pd.DataFrame):\n",
    "            y = np.array(y)\n",
    "\n",
    "        self.tree = self.__create_tree(X, y)\n",
    "       \n",
    "    def __calculate_split_entropy(self, y):\n",
    "        \"\"\"\n",
    "        Calculates the split entropy for a given target variable.\n",
    "\n",
    "        Parameters:\n",
    "        - y: array-like of shape (n_samples,)\n",
    "            The target values.\n",
    "\n",
    "        Returns:\n",
    "        split_criterion: float\n",
    "            The split criterion value.\n",
    "        \"\"\"\n",
    "\n",
    "        unique_values, value_counts = np.unique(y, return_counts=True)\n",
    "        class_probabilities = value_counts / len(y)\n",
    "\n",
    "        if len(self.class_weights) > 0 and len(unique_values) > 0:\n",
    "            class_probabilities *= np.array([self.class_weights.get(value, 1.0) for value in unique_values])\n",
    "\n",
    "        split_criteria = {\n",
    "            'shannon': lambda probs: -np.sum(probs * np.log2(probs)),\n",
    "            'entropy': lambda probs: -np.sum(probs * np.log2(probs + 1e-10)),\n",
    "            'gini': lambda probs:  1 - np.sum(probs ** 2)\n",
    "        }\n",
    "\n",
    "        split_criterion_function = split_criteria.get(self.criterion, split_criteria['gini'])\n",
    "        split_criterion = split_criterion_function(class_probabilities)\n",
    "\n",
    "        return split_criterion\n",
    "\n",
    "\n",
    "    def __calculate_info_gain(self, X, y, feature, threshold):\n",
    "        \"\"\"\n",
    "        Calculates the information gain for a given feature and threshold.\n",
    "\n",
    "        Parameters:\n",
    "        - X: array-like of shape (n_samples, n_features)\n",
    "            The input samples.\n",
    "        - y: array-like of shape (n_samples,)\n",
    "            The target values.\n",
    "        - feature: int\n",
    "            The index of the feature.\n",
    "        - threshold: float\n",
    "            The threshold value.\n",
    "\n",
    "        Returns:\n",
    "        info_gain: float\n",
    "            The information gain.\n",
    "        \"\"\"\n",
    "\n",
    "        left_indeces = X[:, feature] <= threshold\n",
    "        right_indeces = X[:, feature] > threshold\n",
    "\n",
    "        left_labels = y[left_indeces]\n",
    "        right_labels = y[right_indeces]\n",
    "\n",
    "        left_side_entropy = self.__calculate_split_entropy(left_labels)\n",
    "        right_side_entropy = self.__calculate_split_entropy(right_labels)\n",
    "\n",
    "        \n",
    "        weighted_left_side_entropy = (len(left_labels) / len(y)) * left_side_entropy\n",
    "        weighted_right_side_entropy = (len(right_labels) / len(y)) * right_side_entropy\n",
    "\n",
    "        parent_entropy = self.__calculate_split_entropy(y)\n",
    "\n",
    "        info_gain = parent_entropy - (weighted_left_side_entropy + weighted_right_side_entropy)\n",
    "\n",
    "        return info_gain\n",
    "\n",
    "\n",
    "    def __get_features(self, n_features):\n",
    "        \"\"\"\n",
    "        Returns the indices of the features to consider for splitting.\n",
    "\n",
    "        Parameters:\n",
    "        - n_features: int\n",
    "            The total number of features.\n",
    "\n",
    "        Returns:\n",
    "        columns_id: list\n",
    "            The indices of the features to consider.\n",
    "        \"\"\"\n",
    "\n",
    "        np.random.seed(self.random_state + self.node_counter if self.random_state is not None else None)\n",
    "        if self.max_features is not None:\n",
    "            if self.max_features == \"sqrt\":\n",
    "                columns_id = np.random.choice(range(n_features), int(math.sqrt(n_features)), replace=False)\n",
    "            elif self.max_features == \"log2\":\n",
    "                columns_id = np.random.choice(range(n_features), int(math.log2(n_features)), replace=False)\n",
    "            elif isinstance(self.max_features, int):\n",
    "                if self.max_features > n_features:\n",
    "                    raise ValueError(\"Max features > number of features\")\n",
    "                elif self.max_features <= 0:\n",
    "                    raise ValueError(\"Max features must be > 0\")\n",
    "                columns_id = np.random.choice(range(n_features), self.max_features, replace=False)\n",
    "            elif isinstance(self.max_features, float):\n",
    "                if self.max_features > 1:\n",
    "                    raise ValueError(\"Max features > number of features\")\n",
    "                elif self.max_features <= 0:\n",
    "                    raise ValueError(\"Max features must be > 0\")\n",
    "                columns_id = np.random.choice(range(n_features), int(n_features * self.max_features), replace=False)\n",
    "        else:\n",
    "            columns_id = list(range(n_features))    \n",
    "\n",
    "        return columns_id\n",
    "    \n",
    "\n",
    "    def __get_thresholds(self, X, feature):\n",
    "        \"\"\"\n",
    "        Returns the thresholds to consider for a given feature.\n",
    "\n",
    "        Parameters:\n",
    "        - X: array-like of shape (n_samples, n_features)\n",
    "            The input samples.\n",
    "        - feature: int\n",
    "            The index of the feature.\n",
    "\n",
    "        Returns:\n",
    "        thresholds: array-like\n",
    "            The thresholds to consider.\n",
    "        \"\"\"\n",
    "        np.random.seed(self.random_state + self.node_counter if self.random_state is not None else None)\n",
    "        if self.max_thresholds is not None:\n",
    "            if self.max_thresholds <= 0:\n",
    "                raise ValueError(\"max_thresholds must be > 0\")\n",
    "            thresholds = np.percentile(X[:, feature], np.linspace(0, 100, self.max_thresholds))\n",
    "        else:\n",
    "            unique_vals = np.unique(X[:, feature])\n",
    "            thresholds = (unique_vals[1:] + unique_vals[:-1]) / 2\n",
    "        return thresholds\n",
    "\n",
    "\n",
    "\n",
    "    def __calculate_best_split(self, X, y):\n",
    "        \"\"\"\n",
    "        Calculates the best split for the given input samples and target values.\n",
    "\n",
    "        Parameters:\n",
    "        - X: array-like of shape (n_samples, n_features)\n",
    "            The input samples.\n",
    "        - y: array-like of shape (n_samples,)\n",
    "            The target values.\n",
    "\n",
    "        Returns:\n",
    "        best_feature: int\n",
    "            The index of the best feature to split on.\n",
    "        best_threshold: float\n",
    "            The best threshold value.\n",
    "        best_info_gain: float\n",
    "            The information gain of the best split.\n",
    "        \"\"\"\n",
    "\n",
    "        best_threshold = None\n",
    "        best_info_gain = -np.inf\n",
    "        best_feature = None\n",
    "       \n",
    "        features = self.__get_features(X.shape[1])\n",
    "\n",
    "        for feature in features:\n",
    "            threholds = self.__get_thresholds(X, feature)\n",
    "               \n",
    "            for threshold in threholds:\n",
    "                info_gain = self.__calculate_info_gain(X, y, feature, threshold)\n",
    "                self.features_gain_dict[feature] += info_gain\n",
    "                if best_info_gain < info_gain:\n",
    "                    best_threshold = threshold\n",
    "                    best_feature = feature\n",
    "                    best_info_gain = info_gain\n",
    "\n",
    "        return best_feature, best_threshold, best_info_gain\n",
    "\n",
    "\n",
    "    def __create_tree(self, X, y, depth = 0):\n",
    "        \"\"\"\n",
    "        Recursively creates the decision tree.\n",
    "\n",
    "        Parameters:\n",
    "        - X: array-like of shape (n_samples, n_features)\n",
    "            The input samples.\n",
    "        - y: array-like of shape (n_samples,)\n",
    "            The target values.\n",
    "        - depth: int, optional (default=0)\n",
    "            The current depth of the tree.\n",
    "\n",
    "        Returns:\n",
    "        tree: dict\n",
    "            The decision tree.\n",
    "        \"\"\"\n",
    "        samples = X.shape[0]\n",
    "        self.node_counter += 1\n",
    "\n",
    "        if samples < self.min_sample_split or (self.max_depth != None and depth >= self.max_depth):\n",
    "            return self.__create_leaf_node(y)\n",
    "\n",
    "        best_feature, best_threshold, best_info_gain = self.__calculate_best_split(X, y)\n",
    "\n",
    "        if(best_info_gain <= self.min_info_gain):\n",
    "            return self.__create_leaf_node(y)\n",
    "        \n",
    "        left_indices = X[:, best_feature] <= best_threshold\n",
    "        right_indices = X[:, best_feature] > best_threshold\n",
    "\n",
    "        left_child = self.__create_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right_child = self.__create_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "\n",
    "        if 'label' in left_child and 'label' in right_child:\n",
    "            if left_child['label'] == right_child['label']:\n",
    "                return {\n",
    "                    'label': left_child['label'],\n",
    "                    'samples': len(y)\n",
    "                }\n",
    "\n",
    "\n",
    "        return {\n",
    "            'splitting_threshold': best_threshold,\n",
    "            'splitting_feature': best_feature,\n",
    "            'info_gain': best_info_gain,\n",
    "            'left_child': left_child,\n",
    "            'right_child': right_child\n",
    "        }\n",
    "    \n",
    "\n",
    "\n",
    "    def __create_leaf_node(self, y):\n",
    "        \"\"\"\n",
    "        Creates a leaf node for the decision tree.\n",
    "\n",
    "        Parameters:\n",
    "        - y: array-like of shape (n_samples,)\n",
    "            The target values.\n",
    "\n",
    "        Returns:\n",
    "        leaf_node: dict\n",
    "            The leaf node.\n",
    "        \"\"\"\n",
    "        majority_class = Counter(y).most_common(1)[0][0]\n",
    "        return {\n",
    "            'label': majority_class,\n",
    "            'samples': len(y)\n",
    "        }\n",
    "    \n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predicts the class labels for the input samples.\n",
    "\n",
    "        Parameters:\n",
    "        - X: array-like of shape (n_samples, n_features)\n",
    "            The input samples.\n",
    "\n",
    "        Returns:\n",
    "        predictions: array-like of shape (n_samples,)\n",
    "            The predicted class labels.\n",
    "        \"\"\"\n",
    "\n",
    "        if(isinstance(X, pd.DataFrame)):\n",
    "            X = np.array(X)\n",
    "        \n",
    "        predictions = []\n",
    "        for sample in X:\n",
    "            prediction = self.__traverse_tree(sample, self.tree)\n",
    "            predictions.append(prediction)\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        if(isinstance(y, pd.DataFrame)):\n",
    "            y = np.array(y)\n",
    "\n",
    "\n",
    "        y_pred = self.predict(X)\n",
    "\n",
    "        \n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(y_pred, y),\n",
    "            'recall': recall_score(y_pred, y),\n",
    "            'precision': precision_score(y_pred, y),\n",
    "            'f1_score': f1_score(y_pred, y),\n",
    "            #'roc_auc': roc_auc_score(y_pred, y)\n",
    "        }\n",
    "\n",
    "        print(metrics)\n",
    "        print(f\"max_depth: {self.max_depth}, min_sample_split: {self.min_sample_split}, criterion: {self.criterion}, max_features: {self.max_features}, max_thresholds: {self.max_thresholds}\")\n",
    "           \n",
    "        return np.mean(y_pred == y)\n",
    "    \n",
    "\n",
    "    def __traverse_tree(self, sample, node):\n",
    "        \"\"\"\n",
    "        Traverses the decision tree to predict the class label for a given sample.\n",
    "\n",
    "        Parameters:\n",
    "        - sample: array-like of shape (n_features,)\n",
    "            The input sample.\n",
    "        - node: dict\n",
    "            The current node of the decision tree.\n",
    "\n",
    "        Returns:\n",
    "        label: int\n",
    "            The predicted class label.\n",
    "        \"\"\"\n",
    "\n",
    "        if 'label' in node:\n",
    "            return node['label']\n",
    "        else:\n",
    "            if sample[node['splitting_feature']] <= node['splitting_threshold']:\n",
    "                return self.__traverse_tree(sample, node['left_child'])\n",
    "            else:\n",
    "                return self.__traverse_tree(sample, node['right_child'])\n",
    "            \n",
    "    def __recursive_print(self, node, indent=\"\"):\n",
    "        \"\"\"Recursively print the decision tree.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        node\n",
    "            The current node to be printed.\n",
    "        indent : str, default=\"\"\n",
    "            The indentation string for formatting the tree.\n",
    "        \"\"\"\n",
    "        if 'label' in node:\n",
    "            print(\"{}leaf - label: {} \".format(indent, node['label']))\n",
    "            return\n",
    "\n",
    "        print(\"{}id:{} - threshold: {}\".format(indent,\n",
    "              node['splitting_feature'], node['splitting_threshold']))\n",
    "\n",
    "        self.__recursive_print(node['left_child'], \"{}   \".format(indent))\n",
    "        self.__recursive_print(node['right_child'], \"{}   \".format(indent))\n",
    "\n",
    "    def print_tree(self):\n",
    "        \"\"\"Display the decision tree structure.\"\"\"\n",
    "        self.__recursive_print(self.tree)\n",
    "\n",
    "    def get_best_features(self):\n",
    "        total_gain = sum(self.features_gain_dict.values())\n",
    "        \n",
    "        # Normalizza i valori dividendo ogni valore per la somma totale\n",
    "        normalized_features_gain = {k: v / total_gain for k, v in self.features_gain_dict.items()}\n",
    "        \n",
    "        # Restituisci il dizionario ordinato\n",
    "        return {k: v for k, v in sorted(normalized_features_gain.items(), key=lambda item: item[1], reverse=True)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load, split, train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer(as_frame=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(data['data']), np.array(data['target']), test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_s = DecisionTreeClassifier(random_state=0)\n",
    "cls_s.fit(X_train, y_train)\n",
    "cls_s.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_m = DTC(random_state=0)\n",
    "cls_m.fit(X_train, y_train)\n",
    "cls_m.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Decision Tree on transactions\n",
    "Load transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./preprocessed_data/preprocessed_data_small.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(df.drop('is_laundering', axis=1)), np.array(df['is_laundering']), test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"n_samples laundering: {np.sum(y_train)}\")\n",
    "print(f\"n_samples not laundering: {len(y_train) - np.sum(y_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"y_laund_indeces = [i for i,x in enumerate(y_train) if x == 1]\n",
    "y_not_laund_indeces = [i for i,x in enumerate(y_train) if x == 0]\n",
    "\n",
    "X_train_l = [X_train[i] for i in y_laund_indeces]\n",
    "X_train_n = [X_train[i] for i in y_not_laund_indeces]\n",
    "\n",
    "y_train_l = [y_train[i] for i in y_laund_indeces]\n",
    "y_train_n = [y_train[i] for i in y_not_laund_indeces]\n",
    "\n",
    "X_train = np.array(X_train_l + X_train_n[:len(X_train_l)])\n",
    "y_train =  np.array(y_train_l + y_train_n[:len(y_train_l)])\"\"\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet('./preprocessed_data/train_small')\n",
    "train_df = train_df.drop('avg_previous_amount', axis=1).drop('amount_variation', axis=1)\n",
    "test_df = pd.read_parquet('./preprocessed_data/test_small')\n",
    "test_df = test_df.drop('avg_previous_amount', axis=1).drop('amount_variation', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop('is_laundering', axis=1)#.drop('same_account', axis=1).drop('same_amount', axis=1).drop('transaction_received_per_minute', axis=1).drop(\"receiving_currency\",  axis=1).drop(\"payment_currency\",  axis=1).drop(\"same_bank\",  axis=1)\n",
    "#X_train['a1'] = X_train['transaction_send_per_hour']*X_train['daily_trans_between_accounts']\n",
    "#X_train['a2'] = X_train['transaction_send_per_hour']*X_train['num_dest_accounts']\n",
    "y_train = train_df['is_laundering']\n",
    "\n",
    "X_test = test_df.drop('is_laundering', axis=1)#.drop('same_account', axis=1).drop('same_amount', axis=1).drop('transaction_received_per_minute', axis=1).drop(\"receiving_currency\",  axis=1).drop(\"payment_currency\",  axis=1).drop(\"same_bank\",  axis=1)\n",
    "#X_test['a1'] = X_test['transaction_send_per_hour']*X_test['daily_trans_between_accounts']\n",
    "#X_test['a2'] = X_test['transaction_send_per_hour']*X_test['num_dest_accounts']\n",
    "y_test = test_df['is_laundering']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Standardizza i dati\n",
    "scaler = StandardScaler()\n",
    "X_train_standardized = scaler.fit_transform(X_train)\n",
    "scaler = StandardScaler()\n",
    "X_test_standardized = scaler.fit_transform(X_test)\n",
    "\n",
    "\n",
    "pca = PCA(n_components=19)\n",
    "X_train = pca.fit_transform(X_train_standardized)\n",
    "pca = PCA(n_components=19)  # k Ã¨ il numero di componenti principali che desideri mantenere\n",
    "X_test = pca.fit_transform(X_test_standardized)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {0: 1, 1: 1/(sum(y_train)/len(y_train))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t21\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t21\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t21\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t21\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t21\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t21\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t21\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t2\n",
      "Rejected: \t3\n",
      "Iteration: \t9 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t2\n",
      "Rejected: \t3\n",
      "Iteration: \t10 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t2\n",
      "Rejected: \t3\n",
      "Iteration: \t11 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t2\n",
      "Rejected: \t3\n",
      "Iteration: \t12 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t2\n",
      "Rejected: \t3\n",
      "Iteration: \t13 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t2\n",
      "Rejected: \t3\n",
      "Iteration: \t14 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t2\n",
      "Rejected: \t3\n",
      "Iteration: \t15 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t2\n",
      "Rejected: \t3\n",
      "Iteration: \t16 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t2\n",
      "Rejected: \t3\n",
      "Iteration: \t17 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t2\n",
      "Rejected: \t3\n",
      "Iteration: \t18 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t2\n",
      "Rejected: \t3\n",
      "Iteration: \t19 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t2\n",
      "Rejected: \t3\n",
      "Iteration: \t20 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t2\n",
      "Rejected: \t3\n",
      "Iteration: \t21 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t2\n",
      "Rejected: \t3\n",
      "Iteration: \t22 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t2\n",
      "Rejected: \t3\n",
      "Iteration: \t23 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t2\n",
      "Rejected: \t3\n",
      "Iteration: \t24 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t2\n",
      "Rejected: \t3\n",
      "Iteration: \t25 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t2\n",
      "Rejected: \t3\n",
      "Iteration: \t26 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t2\n",
      "Rejected: \t3\n",
      "Iteration: \t27 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t2\n",
      "Rejected: \t3\n",
      "Iteration: \t28 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t2\n",
      "Rejected: \t3\n",
      "Iteration: \t29 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t2\n",
      "Rejected: \t3\n",
      "Iteration: \t30 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t2\n",
      "Rejected: \t3\n",
      "Iteration: \t31 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t2\n",
      "Rejected: \t3\n",
      "Iteration: \t32 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t2\n",
      "Rejected: \t3\n",
      "Iteration: \t33 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t2\n",
      "Rejected: \t3\n",
      "Iteration: \t34 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t35 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t36 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t37 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t38 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t39 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t40 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t41 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t42 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t43 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t44 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t45 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t46 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t47 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t48 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t49 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t50 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t51 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t52 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t53 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t54 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t55 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t56 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t57 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t58 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t59 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t60 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t61 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t62 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t63 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t64 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t65 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t66 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t67 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t68 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t69 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t1\n",
      "Rejected: \t4\n",
      "Iteration: \t70 / 100\n",
      "Confirmed: \t17\n",
      "Tentative: \t0\n",
      "Rejected: \t4\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t71 / 100\n",
      "Confirmed: \t17\n",
      "Tentative: \t0\n",
      "Rejected: \t4\n"
     ]
    }
   ],
   "source": [
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Crea un classificatore Random Forest\n",
    "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced_subsample', n_estimators=30)\n",
    "\n",
    "# Definisci Boruta\n",
    "boruta_selector = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=1)\n",
    "\n",
    "# Addestra Boruta\n",
    "boruta_selector.fit(np.array(X_train.values), np.array(y_train.values.ravel()))\n",
    "\n",
    "# Seleziona le caratteristiche rilevanti\n",
    "X_train_selected = boruta_selector.transform(X_train.values)\n",
    "X_test_selected = boruta_selector.transform(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[True if x == False else False for x in boruta_selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: Index(['day', 'hour', 'minute', 'transaction_received_per_day',\n",
      "       'transaction_received_per_hour', 'transaction_send_per_day',\n",
      "       'transaction_send_per_hour', 'transaction_send_per_minute',\n",
      "       'minutes_since_last_transaction', 'num_unique_payment_formats_last_day',\n",
      "       'num_unique_payment_currency_last_day', 'daily_trans_between_accounts',\n",
      "       'num_dest_accounts', 'payment_currency', 'payment_format',\n",
      "       'same_account', 'same_bank'],\n",
      "      dtype='object')\n",
      "Removed Features: Index(['transaction_received_per_minute', 'receiving_currency',\n",
      "       'same_currency', 'same_amount'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "selected_features = X_train.columns[boruta_selector.support_]\n",
    "removed_features = X_train.columns[[True if x == False else False for x in boruta_selector.support_]]\n",
    "print(\"Selected Features:\", selected_features)\n",
    "print(\"Removed Features:\", removed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9976409637391709, 'recall': 0.373575348248206, 'precision': 0.49248747913188645, 'f1_score': 0.42486797887662026}\n",
      "max_depth: None, min_sample_split: 14, criterion: shannon, max_features: sqrt, max_thresholds: 15\n"
     ]
    }
   ],
   "source": [
    "cls_m = DTC(class_weights=class_weights, max_depth= None, min_sample_split= 14, criterion= \"shannon\", max_features= \"sqrt\", max_thresholds= 15, random_state = 0)\n",
    "cls_m.fit(X_train_selected, y_train)\n",
    "cls_m.score(X_test_selected, y_test)\n",
    "y_pred = cls_m.predict(X_test_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "break\n",
    "# Numero di iterazioni\n",
    "n_iterations = 100\n",
    "\n",
    "# Inizializza un array di zeri per l'importanza delle caratteristiche\n",
    "cumulative_importance = np.zeros(X_train.shape[1])\n",
    "\n",
    "for _ in range(n_iterations):\n",
    "    clf = RandomForestClassifier(n_estimators=24, n_jobs = -1, class_weight='balanced_subsample')\n",
    "    clf.fit(X_train, y_train)\n",
    "    cumulative_importance += clf.feature_importances_\n",
    "\n",
    "# Calcola l'importanza media\n",
    "mean_importance = cumulative_importance / n_iterations\n",
    "\n",
    "# Visualizza l'importanza delle caratteristiche\n",
    "sorted_idx = mean_importance.argsort()\n",
    "plt.barh(range(X_train.shape[1]), mean_importance[sorted_idx])\n",
    "plt.yticks(range(X_train.shape[1]), X_train.columns[sorted_idx])\n",
    "plt.xlabel('Mean Feature Importance')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=24, n_jobs = -1, class_weight='balanced_subsample', random_state=3)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calcola la matrice di confusione\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Etichette delle classi (sostituisci con i tuoi nomi di classi reali se necessario)\n",
    "class_names = ['0', '1']\n",
    "\n",
    "# Crea il grafico della matrice di confusione\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Matrice di Confusione')\n",
    "plt.colorbar()\n",
    "\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names, rotation=45)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "# Aggiungi i valori delle celle nella matrice\n",
    "thresh = cm.max() / 2.0\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.xlabel('Classe Predetta')\n",
    "plt.ylabel('Classe Reale')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet('./preprocessed_data/train_small')\n",
    "train_df = train_df.drop('avg_previous_amount', axis=1).drop('amount_variation', axis=1)\n",
    "val_df = pd.read_parquet('./preprocessed_data/val_small')\n",
    "val_df = val_df.drop('avg_previous_amount', axis=1).drop('amount_variation', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop('is_laundering', axis=1)\n",
    "y_train = train_df['is_laundering']\n",
    "\n",
    "X_val = val_df.drop('is_laundering', axis=1)\n",
    "y_val = val_df['is_laundering']\n",
    "\n",
    "#max_depth: 10, min_sample_split: 14, criterion: shannon, max_features: sqrt, max_thresholds: 15\n",
    "#max_depth: None, min_sample_split: 14, criterion: shannon, max_features: sqrt, max_thresholds: 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {0: 1, 1: 1/(sum(y_train)/len(y_train))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(params):\n",
    "        dtc = DTC(**params, random_state=0, class_weights=class_weights)\n",
    "        dtc.fit(X_train, y_train)\n",
    "        return -dtc.score(X_val, y_val)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choises = {\n",
    "    'max_depth': [5, 10, 15, 20, 25, 30, 35, 40, None],\n",
    "    'min_sample_split': [2, 5, 10, 12, 14, 16, 18, 20],\n",
    "    'criterion': ['gini', 'entropy', 'shannon'],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_thresholds': [2, 4, 6, 8, 10, 15]\n",
    "}\n",
    "\n",
    "space = {\n",
    "    'max_depth': hp.choice('max_depth', choises['max_depth']),\n",
    "    'min_sample_split': hp.choice('min_sample_split', choises['min_sample_split']),\n",
    "    'criterion': hp.choice('criterion', choises['criterion']),\n",
    "    'max_features': hp.choice('max_features', choises['max_features']),\n",
    "    'max_thresholds': hp.choice('max_thresholds', choises['max_thresholds'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective_function, space=space, algo=tpe.suggest, max_evals=2500, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in best.items():\n",
    "    print(f\"{key}: {choises[key][value]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_m.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
