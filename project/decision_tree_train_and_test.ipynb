{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from collections import Counter\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import Pool\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create tree classifier from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class DTC():\n",
    "    def __init__(self, random_state = None, max_depth = None, min_sample_split = 2, criterion = \"gini\", min_info_gain = 0, max_features = None, max_thresholds = None, class_weights = {}):\n",
    "        \"\"\"\n",
    "        Initializes the Decision Tree Classifier.\n",
    "\n",
    "        Parameters:\n",
    "        - random_state: int or None, optional (default=None)\n",
    "            Seed for the random number generator.\n",
    "        - max_depth: int or None, optional (default=None)\n",
    "            The maximum depth of the decision tree. If None, the tree is grown until all leaves are pure or until all leaves contain less than min_sample_split samples.\n",
    "        - min_sample_split: int, optional (default=2)\n",
    "            The minimum number of samples required to split an internal node.\n",
    "        - criterion: str, optional (default=\"gini\")\n",
    "            The function to measure the quality of a split. Supported criteria are \"gini\" for the Gini impurity, \"entropy\" for the information gain, and \"shannon\" for the Shannon entropy.\n",
    "        - min_info_gain: float, optional (default=0)\n",
    "            The minimum information gain required to split an internal node.\n",
    "        - max_features: int, float, \"sqrt\", \"log2\", or None, optional (default=None)\n",
    "            The number of features to consider when looking for the best split. If int, then consider max_features features at each split. If float, then max_features is a fraction and int(max_features * n_features) features are considered. If \"sqrt\", then max_features=sqrt(n_features). If \"log2\", then max_features=log2(n_features). If None, then all features are considered.\n",
    "        - max_thresholds: int or None, optional (default=None)\n",
    "            The maximum number of thresholds to consider for each feature when looking for the best split. If None, all unique feature values are considered as potential thresholds.\n",
    "        - class_weights: dict, optional (default={})\n",
    "            Weights associated with classes. If provided, the class probabilities are multiplied by the corresponding weight.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        \n",
    "        self.max_depth = max_depth\n",
    "        self.min_sample_split = min_sample_split\n",
    "        self.criterion = criterion\n",
    "        self.min_info_gain = min_info_gain\n",
    "        self.max_features = max_features\n",
    "        self.max_thresholds = max_thresholds\n",
    "        self.class_weights = class_weights\n",
    "        self.tree = None\n",
    "        self.random_state = random_state\n",
    "        random.seed(self.random_state)\n",
    "\n",
    "        \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fits the decision tree classifier to the training data.\n",
    "\n",
    "        Parameters:\n",
    "        - X: array-like of shape (n_samples, n_features)\n",
    "            The training input samples.\n",
    "        - y: array-like of shape (n_samples,)\n",
    "            The target values.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = np.array(X)\n",
    "        if isinstance(y, pd.DataFrame):\n",
    "            y = np.array(y)\n",
    "\n",
    "        self.tree = self.__create_tree(X, y)\n",
    "       \n",
    "    def __calculate_split_entropy(self, y):\n",
    "        \"\"\"\n",
    "        Calculates the split entropy for a given target variable.\n",
    "\n",
    "        Parameters:\n",
    "        - y: array-like of shape (n_samples,)\n",
    "            The target values.\n",
    "\n",
    "        Returns:\n",
    "        split_criterion: float\n",
    "            The split criterion value.\n",
    "        \"\"\"\n",
    "\n",
    "        unique_values, value_counts = np.unique(y, return_counts=True)\n",
    "        class_probabilities = value_counts / len(y)\n",
    "\n",
    "        if len(self.class_weights) > 0 and len(unique_values) > 0:\n",
    "            class_probabilities *= np.array([self.class_weights.get(value, 1.0) for value in unique_values])\n",
    "\n",
    "        split_criteria = {\n",
    "            'shannon': lambda probs: -np.sum(probs * np.log2(probs)),\n",
    "            'entropy': lambda probs: -np.sum(probs * np.log2(probs + 1e-10)),\n",
    "            'gini': lambda probs:  1 - np.sum(probs ** 2)\n",
    "        }\n",
    "\n",
    "        split_criterion_function = split_criteria.get(self.criterion, split_criteria['gini'])\n",
    "        split_criterion = split_criterion_function(class_probabilities)\n",
    "\n",
    "        return split_criterion\n",
    "\n",
    "\n",
    "    def __calculate_info_gain(self, X, y, feature, threshold):\n",
    "        \"\"\"\n",
    "        Calculates the information gain for a given feature and threshold.\n",
    "\n",
    "        Parameters:\n",
    "        - X: array-like of shape (n_samples, n_features)\n",
    "            The input samples.\n",
    "        - y: array-like of shape (n_samples,)\n",
    "            The target values.\n",
    "        - feature: int\n",
    "            The index of the feature.\n",
    "        - threshold: float\n",
    "            The threshold value.\n",
    "\n",
    "        Returns:\n",
    "        info_gain: float\n",
    "            The information gain.\n",
    "        \"\"\"\n",
    "\n",
    "        left_indeces = X[:, feature] <= threshold\n",
    "        right_indeces = X[:, feature] > threshold\n",
    "\n",
    "        left_labels = y[left_indeces]\n",
    "        right_labels = y[right_indeces]\n",
    "\n",
    "        left_side_entropy = self.__calculate_split_entropy(left_labels)\n",
    "        right_side_entropy = self.__calculate_split_entropy(right_labels)\n",
    "\n",
    "        \n",
    "        weighted_left_side_entropy = (len(left_labels) / len(y)) * left_side_entropy\n",
    "        weighted_right_side_entropy = (len(right_labels) / len(y)) * right_side_entropy\n",
    "\n",
    "        parent_entropy = self.__calculate_split_entropy(y)\n",
    "\n",
    "        info_gain = parent_entropy - (weighted_left_side_entropy + weighted_right_side_entropy)\n",
    "\n",
    "        return info_gain\n",
    "\n",
    "\n",
    "    def __get_features(self, n_features):\n",
    "        \"\"\"\n",
    "        Returns the indices of the features to consider for splitting.\n",
    "\n",
    "        Parameters:\n",
    "        - n_features: int\n",
    "            The total number of features.\n",
    "\n",
    "        Returns:\n",
    "        columns_id: list\n",
    "            The indices of the features to consider.\n",
    "        \"\"\"\n",
    "\n",
    "        np.random.seed(self.random_state)\n",
    "        if self.max_features is not None:\n",
    "            if self.max_features == \"sqrt\":\n",
    "                columns_id = np.random.choice(range(n_features), int(math.sqrt(n_features)), replace=False)\n",
    "            elif self.max_features == \"log2\":\n",
    "                columns_id = np.random.choice(range(n_features), int(math.log2(n_features)), replace=False)\n",
    "            elif isinstance(self.max_features, int):\n",
    "                if self.max_features > n_features:\n",
    "                    raise ValueError(\"Max features > number of features\")\n",
    "                elif self.max_features <= 0:\n",
    "                    raise ValueError(\"Max features must be > 0\")\n",
    "                columns_id = np.random.choice(range(n_features), self.max_features, replace=False)\n",
    "            elif isinstance(self.max_features, float):\n",
    "                if self.max_features > 1:\n",
    "                    raise ValueError(\"Max features > number of features\")\n",
    "                elif self.max_features <= 0:\n",
    "                    raise ValueError(\"Max features must be > 0\")\n",
    "                columns_id = np.random.choice(range(n_features), int(n_features * self.max_features), replace=False)\n",
    "        else:\n",
    "            columns_id = list(range(n_features))    \n",
    "\n",
    "        return columns_id\n",
    "    \n",
    "\n",
    "    def __get_thresholds(self, X, feature):\n",
    "        \"\"\"\n",
    "        Returns the thresholds to consider for a given feature.\n",
    "\n",
    "        Parameters:\n",
    "        - X: array-like of shape (n_samples, n_features)\n",
    "            The input samples.\n",
    "        - feature: int\n",
    "            The index of the feature.\n",
    "\n",
    "        Returns:\n",
    "        thresholds: array-like\n",
    "            The thresholds to consider.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.max_thresholds is not None:\n",
    "            if self.max_thresholds <= 0:\n",
    "                raise ValueError(\"max_thresholds must be > 0\")\n",
    "            thresholds = np.percentile(X[:, feature], np.linspace(0, 100, self.max_thresholds))\n",
    "        else:\n",
    "            unique_vals = np.unique(X[:, feature])\n",
    "            thresholds = (unique_vals[1:] + unique_vals[:-1]) / 2\n",
    "        return thresholds\n",
    "\n",
    "\n",
    "\n",
    "    def __calculate_best_split(self, X, y):\n",
    "        \"\"\"\n",
    "        Calculates the best split for the given input samples and target values.\n",
    "\n",
    "        Parameters:\n",
    "        - X: array-like of shape (n_samples, n_features)\n",
    "            The input samples.\n",
    "        - y: array-like of shape (n_samples,)\n",
    "            The target values.\n",
    "\n",
    "        Returns:\n",
    "        best_feature: int\n",
    "            The index of the best feature to split on.\n",
    "        best_threshold: float\n",
    "            The best threshold value.\n",
    "        best_info_gain: float\n",
    "            The information gain of the best split.\n",
    "        \"\"\"\n",
    "\n",
    "        best_threshold = None\n",
    "        best_info_gain = -np.inf\n",
    "        best_feature = None\n",
    "\n",
    "        features = self.__get_features(X.shape[1])\n",
    "\n",
    "        for feature in features:\n",
    "            threholds = self.__get_thresholds(X, feature)\n",
    "               \n",
    "            for threshold in threholds:\n",
    "                info_gain = self.__calculate_info_gain(X, y, feature, threshold)\n",
    "                if best_info_gain < info_gain:\n",
    "                    best_threshold = threshold\n",
    "                    best_feature = feature\n",
    "                    best_info_gain = info_gain\n",
    "\n",
    "        return best_feature, best_threshold, best_info_gain\n",
    "\n",
    "\n",
    "    def __create_tree(self, X, y, depth = 0):\n",
    "        \"\"\"\n",
    "        Recursively creates the decision tree.\n",
    "\n",
    "        Parameters:\n",
    "        - X: array-like of shape (n_samples, n_features)\n",
    "            The input samples.\n",
    "        - y: array-like of shape (n_samples,)\n",
    "            The target values.\n",
    "        - depth: int, optional (default=0)\n",
    "            The current depth of the tree.\n",
    "\n",
    "        Returns:\n",
    "        tree: dict\n",
    "            The decision tree.\n",
    "        \"\"\"\n",
    "        samples = X.shape[0]\n",
    "        \n",
    "        if samples < self.min_sample_split or (self.max_depth != None and depth >= self.max_depth):\n",
    "            return self.__create_leaf_node(y)\n",
    "\n",
    "        best_feature, best_threshold, best_info_gain = self.__calculate_best_split(X, y)\n",
    "\n",
    "        if(best_info_gain <= self.min_info_gain):\n",
    "            return self.__create_leaf_node(y)\n",
    "        \n",
    "        left_indices = X[:, best_feature] <= best_threshold\n",
    "        right_indices = X[:, best_feature] > best_threshold\n",
    "\n",
    "        left_child = self.__create_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right_child = self.__create_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "\n",
    "        if 'label' in left_child and 'label' in right_child:\n",
    "            if left_child['label'] == right_child['label']:\n",
    "                return {\n",
    "                    'label': left_child['label'],\n",
    "                    'samples': len(y)\n",
    "                }\n",
    "\n",
    "\n",
    "        return {\n",
    "            'splitting_threshold': best_threshold,\n",
    "            'splitting_feature': best_feature,\n",
    "            'info_gain': best_info_gain,\n",
    "            'left_child': left_child,\n",
    "            'right_child': right_child\n",
    "        }\n",
    "    \n",
    "\n",
    "\n",
    "    def __create_leaf_node(self, y):\n",
    "        \"\"\"\n",
    "        Creates a leaf node for the decision tree.\n",
    "\n",
    "        Parameters:\n",
    "        - y: array-like of shape (n_samples,)\n",
    "            The target values.\n",
    "\n",
    "        Returns:\n",
    "        leaf_node: dict\n",
    "            The leaf node.\n",
    "        \"\"\"\n",
    "        majority_class = Counter(y).most_common(1)[0][0]\n",
    "        return {\n",
    "            'label': majority_class,\n",
    "            'samples': len(y)\n",
    "        }\n",
    "    \n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predicts the class labels for the input samples.\n",
    "\n",
    "        Parameters:\n",
    "        - X: array-like of shape (n_samples, n_features)\n",
    "            The input samples.\n",
    "\n",
    "        Returns:\n",
    "        predictions: array-like of shape (n_samples,)\n",
    "            The predicted class labels.\n",
    "        \"\"\"\n",
    "\n",
    "        if(isinstance(X, pd.DataFrame)):\n",
    "            X = np.array(X)\n",
    "        \n",
    "        predictions = []\n",
    "        for sample in X:\n",
    "            prediction = self.__traverse_tree(sample, self.tree)\n",
    "            predictions.append(prediction)\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        if(isinstance(y, pd.DataFrame)):\n",
    "            y = np.array(y)\n",
    "\n",
    "\n",
    "        y_pred = self.predict(X)\n",
    "\n",
    "        \n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(y_pred, y),\n",
    "            'recall': recall_score(y_pred, y),\n",
    "            'precision': precision_score(y_pred, y),\n",
    "            'f1_score': f1_score(y_pred, y),\n",
    "            'roc_auc': roc_auc_score(y_pred, y)\n",
    "        }\n",
    "\n",
    "        print(metrics)\n",
    "           \n",
    "        return np.mean(y_pred == y)\n",
    "    \n",
    "\n",
    "    def __traverse_tree(self, sample, node):\n",
    "        \"\"\"\n",
    "        Traverses the decision tree to predict the class label for a given sample.\n",
    "\n",
    "        Parameters:\n",
    "        - sample: array-like of shape (n_features,)\n",
    "            The input sample.\n",
    "        - node: dict\n",
    "            The current node of the decision tree.\n",
    "\n",
    "        Returns:\n",
    "        label: int\n",
    "            The predicted class label.\n",
    "        \"\"\"\n",
    "\n",
    "        if 'label' in node:\n",
    "            return node['label']\n",
    "        else:\n",
    "            if sample[node['splitting_feature']] <= node['splitting_threshold']:\n",
    "                return self.__traverse_tree(sample, node['left_child'])\n",
    "            else:\n",
    "                return self.__traverse_tree(sample, node['right_child'])\n",
    "            \n",
    "    def __recursive_print(self, node, indent=\"\"):\n",
    "        \"\"\"Recursively print the decision tree.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        node\n",
    "            The current node to be printed.\n",
    "        indent : str, default=\"\"\n",
    "            The indentation string for formatting the tree.\n",
    "        \"\"\"\n",
    "        if 'label' in node:\n",
    "            print(\"{}leaf - label: {} \".format(indent, node['label']))\n",
    "            return\n",
    "\n",
    "        print(\"{}id:{} - threshold: {}\".format(indent,\n",
    "              node['splitting_feature'], node['splitting_threshold']))\n",
    "\n",
    "        self.__recursive_print(node['left_child'], \"{}   \".format(indent))\n",
    "        self.__recursive_print(node['right_child'], \"{}   \".format(indent))\n",
    "\n",
    "    def print_tree(self):\n",
    "        \"\"\"Display the decision tree structure.\"\"\"\n",
    "        self.__recursive_print(self.tree)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load, split, train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer(as_frame=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(data['data']), np.array(data['target']), test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9385964912280702"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_s = DecisionTreeClassifier(random_state=0)\n",
    "cls_s.fit(X_train, y_train)\n",
    "cls_s.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9385964912280702, 'recall': 0.9571428571428572, 'precision': 0.9436619718309859, 'f1_score': 0.9503546099290779, 'roc_auc': 0.9331168831168831}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9385964912280702"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_m = DTC(random_state=0)\n",
    "cls_m.fit(X_train, y_train)\n",
    "cls_m.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Decision Tree on transactions\n",
    "Load transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>transaction_per_day</th>\n",
       "      <th>transaction_per_hour</th>\n",
       "      <th>transaction_per_minute</th>\n",
       "      <th>receiving_currency</th>\n",
       "      <th>payment_currency</th>\n",
       "      <th>payment_format</th>\n",
       "      <th>same_account</th>\n",
       "      <th>same_bank</th>\n",
       "      <th>same_currency</th>\n",
       "      <th>same_amount</th>\n",
       "      <th>is_laundering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>539</td>\n",
       "      <td>59</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>539</td>\n",
       "      <td>39</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>539</td>\n",
       "      <td>39</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>539</td>\n",
       "      <td>47</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>539</td>\n",
       "      <td>53</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   day  hour  minute  transaction_per_day  transaction_per_hour  \\\n",
       "0    9     3       3                  539                    59   \n",
       "1    2    10       3                  539                    39   \n",
       "2    2    10       3                  539                    39   \n",
       "3    9    14       3                  539                    47   \n",
       "4    2     0       3                  539                    53   \n",
       "\n",
       "   transaction_per_minute  receiving_currency  payment_currency  \\\n",
       "0                      21                   0                 0   \n",
       "1                      21                   0                 0   \n",
       "2                      21                   0                 0   \n",
       "3                      21                   0                 0   \n",
       "4                      21                   0                 0   \n",
       "\n",
       "   payment_format  same_account  same_bank  same_currency  same_amount  \\\n",
       "0               3             0          0              1            1   \n",
       "1               3             0          0              1            1   \n",
       "2               3             0          0              1            1   \n",
       "3               3             0          0              1            1   \n",
       "4               3             0          0              1            1   \n",
       "\n",
       "   is_laundering  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./preprocessed_data/preprocessed_data_small.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(df.drop('is_laundering', axis=1)), np.array(df['is_laundering']), test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples laundering: 4060\n",
      "n_samples not laundering: 4058616\n"
     ]
    }
   ],
   "source": [
    "print(f\"n_samples laundering: {np.sum(y_train)}\")\n",
    "print(f\"n_samples not laundering: {len(y_train) - np.sum(y_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y_laund_indeces = [i for i,x in enumerate(y_train) if x == 1]\\ny_not_laund_indeces = [i for i,x in enumerate(y_train) if x == 0]\\n\\nX_train_l = [X_train[i] for i in y_laund_indeces]\\nX_train_n = [X_train[i] for i in y_not_laund_indeces]\\n\\ny_train_l = [y_train[i] for i in y_laund_indeces]\\ny_train_n = [y_train[i] for i in y_not_laund_indeces]\\n\\nX_train = np.array(X_train_l + X_train_n[:len(X_train_l)])\\ny_train =  np.array(y_train_l + y_train_n[:len(y_train_l)])'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"y_laund_indeces = [i for i,x in enumerate(y_train) if x == 1]\n",
    "y_not_laund_indeces = [i for i,x in enumerate(y_train) if x == 0]\n",
    "\n",
    "X_train_l = [X_train[i] for i in y_laund_indeces]\n",
    "X_train_n = [X_train[i] for i in y_not_laund_indeces]\n",
    "\n",
    "y_train_l = [y_train[i] for i in y_laund_indeces]\n",
    "y_train_n = [y_train[i] for i in y_not_laund_indeces]\n",
    "\n",
    "X_train = np.array(X_train_l + X_train_n[:len(X_train_l)])\n",
    "y_train =  np.array(y_train_l + y_train_n[:len(y_train_l)])\"\"\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {0: 1, 1: 1/sum(y_train)/len(y_train)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_m = DTC(random_state=0, class_weights = class_weights, max_thresholds = 10)\n",
    "cls_m.fit(X_train, y_train)\n",
    "cls_m.score(X_test, y_test)\n",
    "y_pred = cls_m.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calcola la matrice di confusione\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Etichette delle classi (sostituisci con i tuoi nomi di classi reali se necessario)\n",
    "class_names = ['0', '1']\n",
    "\n",
    "# Crea il grafico della matrice di confusione\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Matrice di Confusione')\n",
    "plt.colorbar()\n",
    "\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names, rotation=45)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "# Aggiungi i valori delle celle nella matrice\n",
    "thresh = cm.max() / 2.0\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.xlabel('Classe Predetta')\n",
    "plt.ylabel('Classe Reale')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(params):\n",
    "        dtc = DTC(**params, random_state=0)\n",
    "        dtc.fit(X_train, y_train)\n",
    "        return -dtc.score(X_test, y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choises = {\n",
    "    'max_depth': [None, 5, 10, 15, 20, 25, 30, 35, 40],\n",
    "    'min_sample_split': [2, 5, 10],\n",
    "    'criterion': ['gini', 'entropy', 'shannon'],\n",
    "    'max_features': [None, 'sqrt', 'log2', .2, .4],\n",
    "    'max_thresholds': [None, 2, 4, 6, 8, 10]\n",
    "}\n",
    "\n",
    "space = {\n",
    "    'max_depth': hp.choice('max_depth', choises['max_depth']),\n",
    "    'min_sample_split': hp.choice('min_sample_split', choises['min_sample_split']),\n",
    "    'criterion': hp.choice('criterion', choises['criterion']),\n",
    "    'max_features': hp.choice('max_features', choises['max_features']),\n",
    "    'max_thresholds': hp.choice('max_thresholds', choises['max_thresholds'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective_function, space=space, algo=tpe.suggest, max_evals=2500, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in best.items():\n",
    "    print(f\"{key}: {choises[key][value]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_m.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
