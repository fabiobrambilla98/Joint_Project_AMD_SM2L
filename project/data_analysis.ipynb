{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from pyspark.sql.window import Window\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from graphframes import GraphFrame\n",
    "from pyspark.sql.types import *\n",
    "import multiprocessing\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.stat import Correlation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import functions as F\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/fabio/spark-3.2.4-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.4.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/08/09 20:21:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session created\n",
      "Spark context created\n"
     ]
    }
   ],
   "source": [
    "spark_driver_memory = \"10g\"\n",
    "spark_executor_memory = \"6g\"\n",
    "spark_partial_results_folder = './partial_results'\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "                    .config(\"spark.driver.memory\", spark_driver_memory) \\\n",
    "                    .config(\"spark.executor.memory\", spark_executor_memory) \\\n",
    "                    .master(\"local[*]\") \\\n",
    "                    .config(\"spark.sql.autoBroadcastJoinThreshold\", 100 * 1024 * 1024)\\\n",
    "                    .getOrCreate()\n",
    "print(\"Spark session created\")\n",
    "sc = spark.sparkContext\n",
    "print(\"Spark context created\")\n",
    "\n",
    "\n",
    "if not os.path.exists(spark_partial_results_folder):\n",
    "    os.makedirs(spark_partial_results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField('timestamp', StringType(), True),\n",
    "    StructField('from_bank', IntegerType(), True),\n",
    "    StructField('from_account', StringType(), True),\n",
    "    StructField('to_bank', IntegerType(), True),\n",
    "    StructField('to_account', StringType(), True),\n",
    "    StructField('amount_received', FloatType(), True),\n",
    "    StructField('receiving_currency', StringType(), True),\n",
    "    StructField('amount_paid', FloatType(), True),\n",
    "    StructField('payment_currency', StringType(), True),\n",
    "    StructField('payment_format', StringType(), True),\n",
    "    StructField('is_laundering', IntegerType(), True)])\n",
    "\n",
    "\n",
    "\n",
    "spark_df = spark.read.csv(\"../dataset/HI-Small_Trans.csv\", header = False, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+-------------+-----+\n",
      "|       timestamp|from_bank|from_account|to_bank|to_account|amount_received|receiving_currency|amount_paid|payment_currency|payment_format|is_laundering|index|\n",
      "+----------------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+-------------+-----+\n",
      "|2022/09/01 00:20|       10|   8000EBD30|     10| 8000EBD30|        3697.34|         US Dollar|    3697.34|       US Dollar|  Reinvestment|            0|    1|\n",
      "|2022/09/01 00:20|     3208|   8000F4580|      1| 8000F5340|           0.01|         US Dollar|       0.01|       US Dollar|        Cheque|            0|    2|\n",
      "|2022/09/01 00:00|     3209|   8000F4670|   3209| 8000F4670|       14675.57|         US Dollar|   14675.57|       US Dollar|  Reinvestment|            0|    3|\n",
      "|2022/09/01 00:02|       12|   8000F5030|     12| 8000F5030|        2806.97|         US Dollar|    2806.97|       US Dollar|  Reinvestment|            0|    4|\n",
      "|2022/09/01 00:06|       10|   8000F5200|     10| 8000F5200|       36682.97|         US Dollar|   36682.97|       US Dollar|  Reinvestment|            0|    5|\n",
      "+----------------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+-------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark_df = spark_df.withColumn(\"index\", monotonically_increasing_id())\n",
    "spark_df = spark_df.filter(col('index') > 0)\n",
    "spark_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proportion Laundering and not Laundering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                        (0 + 12) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+---------------------+\n",
      "|is_laundering|count  |proportion           |\n",
      "+-------------+-------+---------------------+\n",
      "|1            |5177   |0.0010194266045335635|\n",
      "|0            |5073168|0.9989805733954664   |\n",
      "+-------------+-------+---------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "total_count = spark_df.count()\n",
    "spark_df.select('is_laundering').groupBy('is_laundering').agg(count('*').alias('count')).withColumn(\"proportion\", col('count')/total_count).show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display payment format in relation to laundering transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+-------+\n",
      "|payment_format|1   |0      |\n",
      "+--------------+----+-------+\n",
      "|ACH           |4483|596314 |\n",
      "|Cheque        |324 |1864007|\n",
      "|Credit Card   |206 |1323118|\n",
      "|Cash          |108 |490783 |\n",
      "|Bitcoin       |56  |146035 |\n",
      "|Reinvestment  |0   |481056 |\n",
      "|Wire          |0   |171855 |\n",
      "+--------------+----+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.select('payment_format', 'is_laundering') \\\n",
    "    .groupBy('payment_format') \\\n",
    "    .agg(\n",
    "        sum(col('is_laundering').cast('int')).alias('1'),\n",
    "        sum((1 - col('is_laundering')).cast('int')).alias('0')\n",
    "    ).orderBy('1', ascending=False).show(truncate=False)\n",
    "\n",
    "# Calculate the number of corresponding values for each value of the \"Payment Format\" and \"Is Laundering\" columns\n",
    "grouped_df = spark_df.groupBy(\"payment_format\", \"is_laundering\").count()\n",
    "\n",
    "# Convert Spark DataFrame to Pandas DataFrame\n",
    "count_values = grouped_df.toPandas()\n",
    "\n",
    "# Use the unstack() method\n",
    "count_values_payment = count_values.pivot(index='payment_format', columns='is_laundering', values='count')\n",
    "\n",
    "# Create a bar chart with a logarithmic scale\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "bar_width = 0.35\n",
    "bar_positions = range(len(count_values_payment.index))\n",
    "axs[0].bar(bar_positions, count_values_payment[0], bar_width, label='Is Laundering = 0')\n",
    "axs[0].bar([p + bar_width for p in bar_positions], count_values_payment[1], bar_width, label='Is Laundering = 1')\n",
    "axs[0].set_xticks(bar_positions)\n",
    "axs[0].set_xticklabels(count_values_payment.index, rotation='vertical') \n",
    "axs[0].set_xlabel('Payment Format')\n",
    "axs[0].set_ylabel('Number of corresponding values')\n",
    "axs[0].set_title('Bar chart in arithmetic scale')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].bar(bar_positions, count_values_payment[0], bar_width, label='Is Laundering = 0')\n",
    "axs[1].bar([p + bar_width for p in bar_positions], count_values_payment[1], bar_width, label='Is Laundering = 1')\n",
    "axs[1].set_xticks(bar_positions)\n",
    "axs[1].set_xticklabels(count_values_payment.index, rotation='vertical') \n",
    "axs[1].set_xlabel('Payment Format')\n",
    "axs[1].set_ylabel('Number of corresponding values')\n",
    "axs[1].set_title('Bar chart in logarithmic scale')\n",
    "axs[1].legend()\n",
    "axs[1].set_yscale('log')\n",
    "\n",
    "# Show the chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display payment currency in relation to laundering transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----+-------+\n",
      "|payment_currency |1   |0      |\n",
      "+-----------------+----+-------+\n",
      "|US Dollar        |1912|1893260|\n",
      "|Euro             |1372|1166925|\n",
      "|Saudi Riyal      |374 |88640  |\n",
      "|Swiss Franc      |193 |234667 |\n",
      "|Yuan             |184 |213568 |\n",
      "|Rupee            |167 |190035 |\n",
      "|Yen              |155 |155054 |\n",
      "|Ruble            |133 |155045 |\n",
      "|UK Pound         |132 |180606 |\n",
      "|Canadian Dollar  |128 |139914 |\n",
      "|Australian Dollar|127 |136642 |\n",
      "|Shekel           |95  |192089 |\n",
      "|Mexican Peso     |92  |110067 |\n",
      "|Brazil Real      |57  |70646  |\n",
      "|Bitcoin          |56  |146010 |\n",
      "+-----------------+----+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df.select('payment_currency', 'is_laundering') \\\n",
    "    .groupBy('payment_currency') \\\n",
    "    .agg(\n",
    "        sum(col('is_laundering').cast('int')).alias('1'),\n",
    "        sum((1 - col('is_laundering')).cast('int')).alias('0')\n",
    "    ).orderBy('1', ascending=False).show(truncate=False)\n",
    "\n",
    "grouped_df = spark_df.groupBy(\"payment_currency\", \"is_laundering\").count()\n",
    "\n",
    "# Convert Spark DataFrame to Pandas DataFrame\n",
    "count_values = grouped_df.toPandas()\n",
    "\n",
    "# Use the unstack() method\n",
    "count_values_currency = count_values.pivot(index='payment_currency', columns='is_laundering', values='count')\n",
    "\n",
    "# Sort the values by Is Laundering = 1 in descending order\n",
    "count_values_currency = count_values_currency.sort_values(1, ascending=False)\n",
    "\n",
    "# Create a bar chart with a logarithmic scale\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "bar_width = 0.35\n",
    "bar_positions = range(len(count_values_currency.index))\n",
    "axs[0].bar(bar_positions, count_values_currency[0], bar_width, label='Is Laundering = 0')\n",
    "axs[0].bar([p + bar_width for p in bar_positions], count_values_currency[1], bar_width, label='Is Laundering = 1')\n",
    "axs[0].set_xticks(bar_positions)\n",
    "axs[0].set_xticklabels(count_values_currency.index, rotation='vertical') \n",
    "axs[0].set_xticklabels(count_values_currency.index)\n",
    "axs[0].set_xlabel('Payment Currency')\n",
    "axs[0].set_ylabel('Number of corresponding values')\n",
    "axs[0].set_title('Bar chart in arithmetic scale')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].bar(bar_positions, count_values_currency[0], bar_width, label='Is Laundering = 0')\n",
    "axs[1].bar([p + bar_width for p in bar_positions], count_values_currency[1], bar_width, label='Is Laundering = 1')\n",
    "axs[1].set_xticks(bar_positions)\n",
    "axs[1].set_xticklabels(count_values_currency.index, rotation='vertical') \n",
    "axs[1].set_xticklabels(count_values_currency.index)\n",
    "axs[1].set_xlabel('Payment Currency')\n",
    "axs[1].set_ylabel('Number of corresponding values')\n",
    "axs[1].set_title('Bar chart in logarithmic scale')\n",
    "axs[1].legend()\n",
    "axs[1].set_yscale('log')\n",
    "\n",
    "# Show the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display top 10 accounts for fraudolent transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:==============================================>         (10 + 2) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+\n",
      "|  account|count_laundering|\n",
      "+---------+----------------+\n",
      "|100428660|             243|\n",
      "|1004286A8|             158|\n",
      "|100428978|              29|\n",
      "|80266F880|              29|\n",
      "|100428810|              26|\n",
      "|812D22980|              25|\n",
      "|100428738|              23|\n",
      "|811C599A0|              21|\n",
      "|811C597B0|              21|\n",
      "|8021353D0|              21|\n",
      "+---------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark_df.select(col('from_account').alias('account'), col('is_laundering'))\\\n",
    ".filter(col('is_laundering') == 1).groupBy('account')\\\n",
    ".agg(count('*').alias('count_laundering'))\\\n",
    ".orderBy('count_laundering', ascending=False)\\\n",
    ".show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display top 20 accounts for transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:====>                                                   (1 + 11) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|  account|count_transactions|\n",
      "+---------+------------------+\n",
      "|100428660|            168672|\n",
      "|1004286A8|            103018|\n",
      "|100428978|             20497|\n",
      "|1004286F0|             18663|\n",
      "|100428780|             17264|\n",
      "|1004289C0|             16794|\n",
      "|100428810|             16426|\n",
      "|1004287C8|             14174|\n",
      "|100428738|             13756|\n",
      "|100428A51|             13073|\n",
      "|1004288A0|             12330|\n",
      "|100428858|             11000|\n",
      "|1004288E8|              9471|\n",
      "|100428A08|              8290|\n",
      "|100428930|              6431|\n",
      "|800058B80|               351|\n",
      "|80006FCE0|               296|\n",
      "|800058920|               279|\n",
      "|80005ADE0|               276|\n",
      "|800105F00|               274|\n",
      "+---------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark_df.select(col('from_account').alias('account'))\\\n",
    ".groupBy('account')\\\n",
    ".agg(count('*').alias('count_transactions'))\\\n",
    ".orderBy('count_transactions', ascending=False)\\\n",
    ".show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display relationhip between amount paid and laundering transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:>                                                       (0 + 12) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+-------------+-------------------+\n",
      "|is_laundering|     min|          max|               mean|\n",
      "+-------------+--------+-------------+-------------------+\n",
      "|            1|0.003227| 8.4853146E10|3.613531071586281E7|\n",
      "|            0|  1.0E-6|1.04630236E12|  4477000.057857941|\n",
      "+-------------+--------+-------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# Estrai il DataFrame Spark come Pandas DataFrame\\ndf_pd = spark_df.toPandas()\\n\\n# Applica la scala logaritmica e la formattazione numerica\\nplt.yscale(\"log\")\\nplt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: format(x, \\',.2f\\')))\\n\\n# Crea il grafico scatter\\nplt.scatter(df_pd[\\'is_laundering\\'], df_pd[\\'amount_paid\\'], alpha=0.5)\\nplt.title(\"Relationship between Is Laundering and Amount Paid\")\\nplt.xlabel(\"Is Laundering\")\\nplt.ylabel(\"Amount Paid\")\\nplt.xticks([0, 1])\\nplt.grid(True)\\nplt.show()'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_stats = spark_df.groupBy('is_laundering').agg(\n",
    "    min(col('amount_paid')).alias('min'),\n",
    "    max(col('amount_paid')).alias('max'),\n",
    "    mean(col('amount_paid')).alias('mean')\n",
    ")\n",
    "\n",
    "# Mostra le statistiche\n",
    "grouped_stats.show()\n",
    "\n",
    "\n",
    "\"\"\"# Estrai il DataFrame Spark come Pandas DataFrame\n",
    "df_pd = spark_df.toPandas()\n",
    "\n",
    "# Applica la scala logaritmica e la formattazione numerica\n",
    "plt.yscale(\"log\")\n",
    "plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: format(x, ',.2f')))\n",
    "\n",
    "# Crea il grafico scatter\n",
    "plt.scatter(df_pd['is_laundering'], df_pd['amount_paid'], alpha=0.5)\n",
    "plt.title(\"Relationship between Is Laundering and Amount Paid\")\n",
    "plt.xlabel(\"Is Laundering\")\n",
    "plt.ylabel(\"Amount Paid\")\n",
    "plt.xticks([0, 1])\n",
    "plt.grid(True)\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+-------------+-----+----+-----+---+----+------+\n",
      "|          timestamp|from_bank|from_account|to_bank|to_account|amount_received|receiving_currency|amount_paid|payment_currency|payment_format|is_laundering|index|year|month|day|hour|minute|\n",
      "+-------------------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+-------------+-----+----+-----+---+----+------+\n",
      "|2022-09-01 00:20:00|       10|   8000EBD30|     10| 8000EBD30|        3697.34|         US Dollar|    3697.34|       US Dollar|  Reinvestment|            0|    1|2022|    9|  1|   0|    20|\n",
      "|2022-09-01 00:20:00|     3208|   8000F4580|      1| 8000F5340|           0.01|         US Dollar|       0.01|       US Dollar|        Cheque|            0|    2|2022|    9|  1|   0|    20|\n",
      "|2022-09-01 00:00:00|     3209|   8000F4670|   3209| 8000F4670|       14675.57|         US Dollar|   14675.57|       US Dollar|  Reinvestment|            0|    3|2022|    9|  1|   0|     0|\n",
      "|2022-09-01 00:02:00|       12|   8000F5030|     12| 8000F5030|        2806.97|         US Dollar|    2806.97|       US Dollar|  Reinvestment|            0|    4|2022|    9|  1|   0|     2|\n",
      "|2022-09-01 00:06:00|       10|   8000F5200|     10| 8000F5200|       36682.97|         US Dollar|   36682.97|       US Dollar|  Reinvestment|            0|    5|2022|    9|  1|   0|     6|\n",
      "+-------------------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+-------------+-----+----+-----+---+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df = spark_df.withColumn(\"timestamp\", to_timestamp(\"timestamp\", \"yyyy/MM/dd HH:mm\"))\n",
    "\n",
    "# Split the timestamp column into separate components\n",
    "spark_df = spark_df.withColumn(\"year\", year(\"timestamp\"))\\\n",
    "                             .withColumn(\"month\", month(\"timestamp\"))\\\n",
    "                             .withColumn(\"day\", dayofmonth(\"timestamp\"))\\\n",
    "                             .withColumn(\"hour\", hour(\"timestamp\"))\\\n",
    "                             .withColumn(\"minute\", minute(\"timestamp\"))\n",
    "spark_df.cache().count()\n",
    "spark_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laundering_for(col_name: str):\n",
    "    print(f\"Laundering for {col_name}\")\n",
    "    spark_df.select(col_name, 'is_laundering') \\\n",
    "    .groupBy(col_name) \\\n",
    "    .agg(\n",
    "        sum(col('is_laundering').cast('int')).alias('count(1)'),\n",
    "        sum((1 - col('is_laundering')).cast('int')).alias('count(0)'),\n",
    "    ).withColumn(\"ratio\", (col('count(1)')/col('count(0)')).cast('Decimal(20,6)')) \\\n",
    "  .orderBy(col('ratio').desc()) \\\n",
    "  .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laundering for year\n",
      "+----+--------+--------+--------+\n",
      "|year|count(1)|count(0)|ratio   |\n",
      "+----+--------+--------+--------+\n",
      "|2022|5177    |5073168 |0.001020|\n",
      "+----+--------+--------+--------+\n",
      "\n",
      "Laundering for month\n",
      "+-----+--------+--------+--------+\n",
      "|month|count(1)|count(0)|ratio   |\n",
      "+-----+--------+--------+--------+\n",
      "|9    |5177    |5073168 |0.001020|\n",
      "+-----+--------+--------+--------+\n",
      "\n",
      "Laundering for day\n",
      "+---+--------+--------+--------+\n",
      "|day|count(1)|count(0)|ratio   |\n",
      "+---+--------+--------+--------+\n",
      "|18 |8       |3       |2.666667|\n",
      "|17 |15      |8       |1.875000|\n",
      "|15 |28      |18      |1.555556|\n",
      "|12 |170     |111     |1.531532|\n",
      "|11 |232     |164     |1.414634|\n",
      "|14 |70      |51      |1.372549|\n",
      "|13 |106     |78      |1.358974|\n",
      "|16 |26      |20      |1.300000|\n",
      "|10 |442     |207883  |0.002126|\n",
      "|4  |407     |207023  |0.001966|\n",
      "|3  |391     |206991  |0.001889|\n",
      "|8  |539     |482234  |0.001118|\n",
      "|6  |531     |481558  |0.001103|\n",
      "|7  |497     |482254  |0.001031|\n",
      "|5  |471     |482179  |0.000977|\n",
      "|9  |514     |653953  |0.000786|\n",
      "|2  |408     |754041  |0.000541|\n",
      "|1  |322     |1114599 |0.000289|\n",
      "+---+--------+--------+--------+\n",
      "\n",
      "Laundering for hour\n",
      "+----+--------+--------+--------+\n",
      "|hour|count(1)|count(0)|ratio   |\n",
      "+----+--------+--------+--------+\n",
      "|12  |336     |192636  |0.001744|\n",
      "|16  |311     |193096  |0.001611|\n",
      "|11  |295     |193205  |0.001527|\n",
      "|13  |292     |192229  |0.001519|\n",
      "|14  |279     |192508  |0.001449|\n",
      "|15  |263     |194608  |0.001351|\n",
      "|8   |258     |192663  |0.001339|\n",
      "|17  |257     |192897  |0.001332|\n",
      "|18  |255     |193066  |0.001321|\n",
      "|10  |234     |192995  |0.001212|\n",
      "|19  |231     |192593  |0.001199|\n",
      "|9   |217     |192735  |0.001126|\n",
      "|6   |207     |194249  |0.001066|\n",
      "|7   |195     |193141  |0.001010|\n",
      "|5   |188     |193712  |0.000971|\n",
      "|2   |165     |192978  |0.000855|\n",
      "|21  |154     |192038  |0.000802|\n",
      "|4   |154     |193012  |0.000798|\n",
      "|1   |152     |193576  |0.000785|\n",
      "|23  |150     |193195  |0.000776|\n",
      "+----+--------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Laundering for minute\n",
      "+------+--------+--------+--------+\n",
      "|minute|count(1)|count(0)|ratio   |\n",
      "+------+--------+--------+--------+\n",
      "|44    |104     |76765   |0.001355|\n",
      "|49    |98      |77188   |0.001270|\n",
      "|33    |95      |76608   |0.001240|\n",
      "|57    |93      |77737   |0.001196|\n",
      "|53    |91      |77268   |0.001178|\n",
      "|48    |91      |77232   |0.001178|\n",
      "|32    |90      |76985   |0.001169|\n",
      "|56    |90      |77096   |0.001167|\n",
      "|31    |89      |76972   |0.001156|\n",
      "|36    |89      |76983   |0.001156|\n",
      "|55    |89      |77091   |0.001154|\n",
      "|14    |106     |92078   |0.001151|\n",
      "|43    |88      |76807   |0.001146|\n",
      "|50    |88      |76891   |0.001144|\n",
      "|39    |88      |77141   |0.001141|\n",
      "|51    |86      |77080   |0.001116|\n",
      "|11    |100     |90994   |0.001099|\n",
      "|42    |84      |77000   |0.001091|\n",
      "|16    |100     |91917   |0.001088|\n",
      "|59    |84      |77380   |0.001086|\n",
      "+------+--------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "laundering_for('year')\n",
    "laundering_for('month')\n",
    "laundering_for('day')\n",
    "laundering_for('hour')\n",
    "laundering_for('minute')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count the number of transaction an account receive in different period of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_trans_received(df):\n",
    "    window = Window.partitionBy('to_account', 'day')\n",
    "    df = df.withColumn(\"transaction_received_per_day\", count('*').over(window))\n",
    "\n",
    "    window = Window.partitionBy('to_account', 'hour')\n",
    "    df = df.withColumn(\"transaction_received_per_hour\", count('*').over(window))\n",
    "\n",
    "    window = Window.partitionBy('to_account', 'minute')\n",
    "    df = df.withColumn(\"transaction_received_per_minute\", count('*').over(window))\n",
    "\n",
    "    return df.coalesce(48)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = add_trans_received(spark_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count the number of transaction an account send in different period of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_trans_send(df):\n",
    "    window = Window.partitionBy('from_account', 'day')\n",
    "    df = df.withColumn(\"transaction_send_per_day\", count('*').over(window))\n",
    "\n",
    "    window = Window.partitionBy('from_account', 'hour')\n",
    "    df = df.withColumn(\"transaction_send_per_hour\", count('*').over(window))\n",
    "\n",
    "    window = Window.partitionBy('from_account', 'minute')\n",
    "    df = df.withColumn(\"transaction_send_per_minute\", count('*').over(window))\n",
    "\n",
    "    return df.coalesce(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = add_trans_send(spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 67:===================================================>    (12 + 1) / 13]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+-------------+-----------+----+-----+---+----+------+----------------------------+-----------------------------+-------------------------------+------------------------+-------------------------+---------------------------+\n",
      "|          timestamp|from_bank|from_account|to_bank|to_account|amount_received|receiving_currency|amount_paid|payment_currency|payment_format|is_laundering|      index|year|month|day|hour|minute|transaction_received_per_day|transaction_received_per_hour|transaction_received_per_minute|transaction_send_per_day|transaction_send_per_hour|transaction_send_per_minute|\n",
      "+-------------------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+-------------+-----------+----+-----+---+----+------+----------------------------+-----------------------------+-------------------------------+------------------------+-------------------------+---------------------------+\n",
      "|2022-09-10 03:03:00|       70|   100428660|  40933| 810E7E2C0|         160.56|         US Dollar|     160.56|       US Dollar|   Credit Card|            0|94489497253|2022|    9| 10|   3|     3|                           2|                            2|                              1|                    7440|                     6971|                       2937|\n",
      "|2022-09-10 03:03:00|       70|   100428660|  11471| 800954DB0|        1566.88|         US Dollar|    1566.88|       US Dollar|        Cheque|            0|94489496034|2022|    9| 10|   3|     3|                           2|                            2|                              1|                    7440|                     6971|                       2937|\n",
      "|2022-09-10 03:03:00|       70|   100428660|  22345| 802025B40|         791.76|         US Dollar|     791.76|       US Dollar|   Credit Card|            0|94489496190|2022|    9| 10|   3|     3|                           2|                            2|                              1|                    7440|                     6971|                       2937|\n",
      "|2022-09-10 03:03:00|       70|   100428660| 239330| 810E7D6A0|         165.56|         US Dollar|     165.56|       US Dollar|        Cheque|            0|94489497249|2022|    9| 10|   3|     3|                           3|                            3|                              1|                    7440|                     6971|                       2937|\n",
      "|2022-09-10 03:03:00|       70|   100428660|  11318| 806646150|          34.27|         US Dollar|      34.27|       US Dollar|   Credit Card|            0|94489496483|2022|    9| 10|   3|     3|                           2|                            4|                              1|                    7440|                     6971|                       2937|\n",
      "|2022-09-09 03:03:00|       70|   100428660| 136110| 80E165930|          31.41|         US Dollar|      31.41|       US Dollar|          Cash|            0|85899395597|2022|    9|  9|   3|     3|                           3|                            3|                              1|                   22542|                     6971|                       2937|\n",
      "|2022-09-09 03:03:00|       70|   100428660|  17907| 80B638D50|       65165.87|         US Dollar|   65165.87|       US Dollar|        Cheque|            0|85899394875|2022|    9|  9|   3|     3|                           4|                            1|                              2|                   22542|                     6971|                       2937|\n",
      "|2022-09-09 03:03:00|       70|   100428660|  16109| 811093CB0|        2450.61|         US Dollar|    2450.61|       US Dollar|        Cheque|            0|85899396124|2022|    9|  9|   3|     3|                           5|                            1|                              1|                   22542|                     6971|                       2937|\n",
      "|2022-09-09 03:03:00|       70|   100428660|    220| 800C42AC0|        2241.02|         US Dollar|    2241.02|       US Dollar|   Credit Card|            0|85899392375|2022|    9|  9|   3|     3|                           2|                            2|                              2|                   22542|                     6971|                       2937|\n",
      "|2022-09-09 03:03:00|       70|   100428660|  11904| 801626890|         155.88|         US Dollar|     155.88|       US Dollar|        Cheque|            0|85899392615|2022|    9|  9|   3|     3|                           2|                            4|                              1|                   22542|                     6971|                       2937|\n",
      "|2022-09-09 03:03:00|       70|   100428660|  23537| 801DD8640|           97.7|         US Dollar|       97.7|       US Dollar|          Cash|            0|85899392779|2022|    9|  9|   3|     3|                           3|                            3|                              1|                   22542|                     6971|                       2937|\n",
      "|2022-09-09 03:03:00|       70|   100428660| 123773| 80B41CE10|        5818.81|         US Dollar|    5818.81|       US Dollar|   Credit Card|            0|85899394819|2022|    9|  9|   3|     3|                           2|                            3|                              1|                   22542|                     6971|                       2937|\n",
      "|2022-09-09 03:03:00|       70|   100428660| 135290| 80D456820|          83.25|         US Dollar|      83.25|       US Dollar|   Credit Card|            0|85899395368|2022|    9|  9|   3|     3|                           3|                            3|                              1|                   22542|                     6971|                       2937|\n",
      "|2022-09-09 03:03:00|       70|   100428660|   1686| 80EECB8B0|       33089.84|         US Dollar|   33089.84|       US Dollar|        Cheque|            0|85899395775|2022|    9|  9|   3|     3|                           3|                            9|                              1|                   22542|                     6971|                       2937|\n",
      "|2022-09-09 03:03:00|       70|   100428660|   2952| 801940410|         399.71|         US Dollar|     399.71|       US Dollar|        Cheque|            0|85899392682|2022|    9|  9|   3|     3|                           2|                            2|                              1|                   22542|                     6971|                       2937|\n",
      "|2022-09-09 03:03:00|       70|   100428660|   2991| 80D25FEF0|        12477.7|         US Dollar|    12477.7|       US Dollar|        Cheque|            0|85899395341|2022|    9|  9|   3|     3|                           3|                            1|                              2|                   22542|                     6971|                       2937|\n",
      "|2022-09-09 03:03:00|       70|   100428660|    701| 8006A3A80|           9.25|         US Dollar|       9.25|       US Dollar|        Cheque|            0|85899392222|2022|    9|  9|   3|     3|                           2|                            6|                              1|                   22542|                     6971|                       2937|\n",
      "|2022-09-09 03:03:00|       70|   100428660|  18015| 8031836B0|        4435.88|         US Dollar|    4435.88|       US Dollar|   Credit Card|            0|85899393085|2022|    9|  9|   3|     3|                           3|                            2|                              1|                   22542|                     6971|                       2937|\n",
      "|2022-09-09 03:03:00|       70|   100428660| 118453| 8081D8F80|        1493.43|         US Dollar|    1493.43|       US Dollar|        Cheque|            0|85899394158|2022|    9|  9|   3|     3|                           2|                            4|                              1|                   22542|                     6971|                       2937|\n",
      "|2022-09-09 03:03:00|       70|   100428660|   1292| 8002D6970|          10.01|         US Dollar|      10.01|       US Dollar|   Credit Card|            0|85899392162|2022|    9|  9|   3|     3|                           3|                            2|                              1|                   22542|                     6971|                       2937|\n",
      "+-------------------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+-------------+-----------+----+-----+---+----+------+----------------------------+-----------------------------+-------------------------------+------------------------+-------------------------+---------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 32:===================================================>    (12 + 1) / 13]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+-------------+-----------+----+-----+---+----+------+----------------------------+-----------------------------+-------------------------------+------------------------+-------------------------+---------------------------+------------------------------+\n",
      "|          timestamp|from_bank|from_account|to_bank|to_account|amount_received|receiving_currency|amount_paid|payment_currency|payment_format|is_laundering|      index|year|month|day|hour|minute|transaction_received_per_day|transaction_received_per_hour|transaction_received_per_minute|transaction_send_per_day|transaction_send_per_hour|transaction_send_per_minute|minutes_since_last_transaction|\n",
      "+-------------------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+-------------+-----------+----+-----+---+----+------+----------------------------+-----------------------------+-------------------------------+------------------------+-------------------------+---------------------------+------------------------------+\n",
      "|2022-09-01 00:19:00|       12|   8000436D0|     12| 8000436D0|        1295.66|              Euro|    1295.66|            Euro|  Reinvestment|            0|     122758|2022|    9|  1|   0|    19|                           4|                            2|                              1|                       2|                        1|                          1|                          -1.0|\n",
      "|2022-09-01 16:02:00|       12|   8000436D0|     12| 8000436D0|          20.95|              Euro|      20.95|            Euro|  Reinvestment|            0|17179889595|2022|    9|  1|  16|     2|                           4|                            1|                              1|                       2|                        1|                          1|                         943.0|\n",
      "|2022-09-02 22:32:00|       12|   8000436D0|  17769| 804900CE0|         293.23|              Euro|     293.23|            Euro|           ACH|            0|34359884758|2022|    9|  2|  22|    32|                           6|                            5|                              1|                       3|                        3|                          1|                        1830.0|\n",
      "|2022-09-02 22:39:00|       12|   8000436D0|  17769| 804900CE0|        7472.24|              Euro|    7472.24|            Euro|   Credit Card|            0|34359884756|2022|    9|  2|  22|    39|                           6|                            5|                              1|                       3|                        3|                          1|                           7.0|\n",
      "|2022-09-02 22:54:00|       12|   8000436D0|  17769| 804900CE0|        3296.19|              Euro|    3296.19|            Euro|          Cash|            0|34359884757|2022|    9|  2|  22|    54|                           6|                            5|                              1|                       3|                        3|                          1|                          15.0|\n",
      "|2022-09-09 15:03:00|       12|   8000436D0|  17769| 804900CE0|        3296.19|              Euro|    3296.19|            Euro|          Cash|            0|85899718162|2022|    9|  9|  15|     3|                           5|                            3|                              1|                       3|                        3|                          1|                        9609.0|\n",
      "|2022-09-09 15:06:00|       12|   8000436D0|  17769| 804900CE0|        7472.24|              Euro|    7472.24|            Euro|   Credit Card|            0|85899718161|2022|    9|  9|  15|     6|                           5|                            3|                              2|                       3|                        3|                          2|                           3.0|\n",
      "|2022-09-09 15:06:00|       12|   8000436D0|  17769| 804900CE0|         293.23|              Euro|     293.23|            Euro|           ACH|            0|85899718163|2022|    9|  9|  15|     6|                           5|                            3|                              2|                       3|                        3|                          2|                           0.0|\n",
      "|2022-09-01 00:14:00|       10|   800043990|     10| 800043990|          23.63|         US Dollar|      23.63|       US Dollar|  Reinvestment|            0|        103|2022|    9|  1|   0|    14|                           3|                            2|                              1|                      24|                        8|                          4|                          -1.0|\n",
      "|2022-09-01 00:56:00|       10|   800043990|     10| 800043990|        3221.56|         US Dollar|    3221.56|       US Dollar|        Cheque|            0|     327426|2022|    9|  1|   0|    56|                           3|                            2|                              1|                      24|                        8|                          4|                          42.0|\n",
      "|2022-09-01 04:01:00|       10|   800043990|      1| 8001C76F0|          35.18|         US Dollar|      35.18|       US Dollar|   Credit Card|            0| 8589967608|2022|    9|  1|   4|     1|                           4|                            2|                              1|                      24|                        9|                          4|                         185.0|\n",
      "|2022-09-01 04:11:00|       10|   800043990|      1| 8001C76F0|          39.21|         US Dollar|      39.21|       US Dollar|        Cheque|            0| 8589967607|2022|    9|  1|   4|    11|                           4|                            2|                              1|                      24|                        9|                          3|                          10.0|\n",
      "|2022-09-01 06:42:00|       10|   800043990|     12| 8001F7C90|         183.42|         US Dollar|     183.42|       US Dollar|   Credit Card|            0| 8590051109|2022|    9|  1|   6|    42|                           3|                            4|                              1|                      24|                       15|                          6|                         151.0|\n",
      "|2022-09-01 06:51:00|       10|   800043990|     12| 8001F7C90|          41.89|         US Dollar|      41.89|       US Dollar|        Cheque|            0| 8590051108|2022|    9|  1|   6|    51|                           3|                            4|                              2|                      24|                       15|                          5|                           9.0|\n",
      "|2022-09-01 10:04:00|       10|   800043990|  11296| 8007A88C0|       292007.7|         US Dollar|   292007.7|       US Dollar|           ACH|            0| 8590168194|2022|    9|  1|  10|     4|                           4|                            4|                              1|                      24|                        8|                          4|                         193.0|\n",
      "|2022-09-01 10:13:00|       10|   800043990|  11296| 8007A88C0|       272950.9|         US Dollar|   272950.9|       US Dollar|        Cheque|            0| 8590168193|2022|    9|  1|  10|    13|                           4|                            4|                              1|                      24|                        8|                          4|                           9.0|\n",
      "|2022-09-01 13:19:00|       10|   800043990|     10| 800146140|         248.42|         US Dollar|     248.42|       US Dollar|        Cheque|            0| 8590268859|2022|    9|  1|  13|    19|                           7|                            2|                              1|                      24|                        4|                          4|                         186.0|\n",
      "|2022-09-01 13:20:00|       10|   800043990|     10| 800146140|         101.13|         US Dollar|     101.13|       US Dollar|          Cash|            0| 8590268860|2022|    9|  1|  13|    20|                           7|                            2|                              2|                      24|                        4|                          3|                           1.0|\n",
      "|2022-09-01 14:34:00|       10|   800043990|      1| 80011E2A0|        7960.31|         US Dollar|    7960.31|       US Dollar|   Credit Card|            0| 8590319250|2022|    9|  1|  14|    34|                           4|                            3|                              2|                      24|                        7|                          5|                          74.0|\n",
      "|2022-09-01 14:36:00|       10|   800043990|      1| 80011E2A0|       30955.03|         US Dollar|   30955.03|       US Dollar|        Cheque|            0| 8590319249|2022|    9|  1|  14|    36|                           4|                            3|                              1|                      24|                        7|                          4|                           2.0|\n",
      "+-------------------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+-------------+-----------+----+-----+---+----+------+----------------------------+-----------------------------+-------------------------------+------------------------+-------------------------+---------------------------+------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "windowSpec = Window.partitionBy(\"from_account\").orderBy(\"timestamp\")\n",
    "\n",
    "# Usa la funzione 'lag' per ottenere il timestamp della transazione precedente\n",
    "spark_df = spark_df.withColumn(\"prev_timestamp\", F.lag(spark_df.timestamp).over(windowSpec))\n",
    "\n",
    "# Calcola la differenza in minuti\n",
    "spark_df = spark_df.withColumn(\n",
    "    \"minutes_since_last_transaction\", \n",
    "    F.when(\n",
    "        F.isnull(spark_df.prev_timestamp), \n",
    "        -1\n",
    "    ).otherwise(\n",
    "        (F.unix_timestamp(spark_df.timestamp) - F.unix_timestamp(spark_df.prev_timestamp)) / 60\n",
    "    )\n",
    ")\n",
    "\n",
    "# Seleziona le colonne desiderate\n",
    "spark_df = spark_df.drop(\"prev_timestamp\")\n",
    "\n",
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 84:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+-------------+-----------+----+-----+---+----+------+----------------------------+-----------------------------+-------------------------------+------------------------+-------------------------+---------------------------+------------------------------+-------------------+-------------------+\n",
      "|          timestamp|from_bank|from_account|to_bank|to_account|amount_received|receiving_currency|amount_paid|payment_currency|payment_format|is_laundering|      index|year|month|day|hour|minute|transaction_received_per_day|transaction_received_per_hour|transaction_received_per_minute|transaction_send_per_day|transaction_send_per_hour|transaction_send_per_minute|minutes_since_last_transaction|avg_previous_amount|   amount_variation|\n",
      "+-------------------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+-------------+-----------+----+-----+---+----+------+----------------------------+-----------------------------+-------------------------------+------------------------+-------------------------+---------------------------+------------------------------+-------------------+-------------------+\n",
      "|2022-09-01 00:19:00|       12|   8000436D0|     12| 8000436D0|        1295.66|              Euro|    1295.66|            Euro|  Reinvestment|            0|     122758|2022|    9|  1|   0|    19|                           4|                            2|                              1|                       2|                        1|                          1|                          -1.0|                0.0| 1295.6600341796875|\n",
      "|2022-09-01 16:02:00|       12|   8000436D0|     12| 8000436D0|          20.95|              Euro|      20.95|            Euro|  Reinvestment|            0|17179889595|2022|    9|  1|  16|     2|                           4|                            1|                              1|                       2|                        1|                          1|                         943.0| 1295.6600341796875| -1274.710033416748|\n",
      "|2022-09-02 22:32:00|       12|   8000436D0|  17769| 804900CE0|         293.23|              Euro|     293.23|            Euro|           ACH|            0|34359884758|2022|    9|  2|  22|    32|                           6|                            5|                              1|                       3|                        3|                          1|                        1830.0|  658.3050174713135|-365.07500648498535|\n",
      "|2022-09-02 22:39:00|       12|   8000436D0|  17769| 804900CE0|        7472.24|              Euro|    7472.24|            Euro|   Credit Card|            0|34359884756|2022|    9|  2|  22|    39|                           6|                            5|                              1|                       3|                        3|                          1|                           7.0|   536.613348642985|  6935.626885732015|\n",
      "|2022-09-02 22:54:00|       12|   8000436D0|  17769| 804900CE0|        3296.19|              Euro|    3296.19|            Euro|          Cash|            0|34359884757|2022|    9|  2|  22|    54|                           6|                            5|                              1|                       3|                        3|                          1|                          15.0| 2270.5200700759888| 1025.6698713302612|\n",
      "|2022-09-09 15:03:00|       12|   8000436D0|  17769| 804900CE0|        3296.19|              Euro|    3296.19|            Euro|          Cash|            0|85899718162|2022|    9|  9|  15|     3|                           5|                            3|                              1|                       3|                        3|                          1|                        9609.0|  2475.654044342041|  820.5358970642092|\n",
      "|2022-09-09 15:06:00|       12|   8000436D0|  17769| 804900CE0|        7472.24|              Euro|    7472.24|            Euro|   Credit Card|            0|85899718161|2022|    9|  9|  15|     6|                           5|                            3|                              2|                       3|                        3|                          2|                           3.0| 2612.4100271860757|  4859.830207188925|\n",
      "|2022-09-09 15:06:00|       12|   8000436D0|  17769| 804900CE0|         293.23|              Euro|     293.23|            Euro|           ACH|            0|85899718163|2022|    9|  9|  15|     6|                           5|                            3|                              2|                       3|                        3|                          2|                           0.0|  3306.671485355922| -3013.441474369594|\n",
      "|2022-09-01 00:07:00|      212|   800095380| 220541| 807715EE0|        38549.7|          UK Pound|    38549.7|        UK Pound|        Cheque|            0|     245234|2022|    9|  1|   0|     7|                           7|                            6|                              2|                      16|                        6|                          1|                          -1.0|                0.0|     38549.69921875|\n",
      "|2022-09-01 00:09:00|      212|   800095380| 220541| 807715EE0|        8666.14|          UK Pound|    8666.14|        UK Pound|   Credit Card|            0|     245235|2022|    9|  1|   0|     9|                           7|                            6|                              1|                      16|                        6|                          1|                           2.0|     38549.69921875|  -29883.5595703125|\n",
      "|2022-09-01 00:21:00|      212|   800095380| 220541| 807715EE0|        1808.27|          UK Pound|    1808.27|        UK Pound|          Wire|            0|     245236|2022|    9|  1|   0|    21|                           7|                            6|                              1|                      16|                        6|                          2|                          12.0|  23607.91943359375|  -21799.6494140625|\n",
      "|2022-09-01 00:28:00|      212|   800095380|    212| 800095380|          15.18|          UK Pound|      15.18|        UK Pound|  Reinvestment|            0|     244661|2022|    9|  1|   0|    28|                           5|                            1|                              2|                      16|                        6|                          5|                           7.0|  16341.36962890625|-16326.189628601074|\n",
      "|2022-09-01 05:24:00|      212|   800095380|    212| 800095380|         240.71|          UK Pound|     240.71|        UK Pound|        Cheque|            0| 8590013115|2022|    9|  1|   5|    24|                           5|                            2|                              1|                      16|                        7|                          2|                         296.0| 12259.822221755981|-12019.112215042114|\n",
      "|2022-09-01 07:05:00|      212|   800095380| 120292| 807C2CB50|        1851.25|          UK Pound|    1851.25|        UK Pound|        Cheque|            0| 8590080646|2022|    9|  1|   7|     5|                           7|                            2|                              1|                      16|                        2|                          4|                         101.0|  9855.999778747559| -8004.749778747559|\n",
      "|2022-09-01 07:25:00|      212|   800095380| 120292| 807C2CB50|        1403.25|          UK Pound|    1403.25|        UK Pound|   Credit Card|            0| 8590080647|2022|    9|  1|   7|    25|                           7|                            2|                              1|                      16|                        2|                          1|                          20.0|  8521.874815622965| -7118.624815622965|\n",
      "|2022-09-01 09:03:00|      212|   800095380|    212| 807E6DA20|         168.17|          UK Pound|     168.17|        UK Pound|        Cheque|            0| 8590147269|2022|    9|  1|   9|     3|                           3|                            2|                              1|                      16|                       10|                          2|                          98.0|  7504.928413391113| -7336.758415222168|\n",
      "|2022-09-01 09:27:00|      212|   800095380|    212| 807E6DA20|          59.21|          UK Pound|      59.21|        UK Pound|           ACH|            0| 8590147270|2022|    9|  1|   9|    27|                           3|                            2|                              2|                      16|                       10|                          3|                          24.0|  6587.833611488342|  -6528.62361240387|\n",
      "|2022-09-01 11:13:00|      212|   800095380|  22422| 808ABDBA0|          106.2|          UK Pound|      106.2|        UK Pound|        Cheque|            0| 8590214458|2022|    9|  1|  11|    13|                           2|                            4|                              1|                      16|                       11|                          4|                         106.0|  5862.430987887912|  -5756.23099093967|\n",
      "|2022-09-01 11:27:00|      212|   800095380|  22422| 808ABDBA0|         989.15|          UK Pound|     989.15|        UK Pound|   Credit Card|            0| 8590214459|2022|    9|  1|  11|    27|                           2|                            4|                              1|                      16|                       11|                          3|                          14.0| 5286.8078887939455| -4297.657864379883|\n",
      "|2022-09-01 12:13:00|      212|   800095380|    212| 800095380|          201.6|          UK Pound|      201.6|        UK Pound|   Credit Card|            0| 8590247958|2022|    9|  1|  12|    13|                           5|                            3|                              2|                      16|                        3|                          4|                          46.0|  4896.111719304865| -4694.511713201349|\n",
      "+-------------------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+-------------+-----------+----+-----+---+----+------+----------------------------+-----------------------------+-------------------------------+------------------------+-------------------------+---------------------------+------------------------------+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "windowSpec = Window.partitionBy(\"from_account\").orderBy(\"timestamp\").rowsBetween(Window.unboundedPreceding, -1)\n",
    "\n",
    "# Calcola l'importo medio delle transazioni precedenti\n",
    "spark_df = spark_df.withColumn(\"avg_previous_amount\", F.coalesce(F.avg(\"amount_received\").over(windowSpec), F.lit(0)))\n",
    "\n",
    "# Calcola la variazione dell'importo e utilizza 0 come valore di default se è nulla\n",
    "spark_df = spark_df.withColumn(\"amount_variation\", F.coalesce(F.col(\"amount_received\") - F.col(\"avg_previous_amount\"), F.lit(0)))\n",
    "\n",
    "# Mostra il risultato\n",
    "spark_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/09 20:08:38 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 76:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+-------------+-----------+----+-----+---+----+------+----------------------------+-----------------------------+-------------------------------+------------------------+-------------------------+---------------------------+------------------------------+------------------------+---------------------------+\n",
      "|          timestamp|from_bank|from_account|to_bank|to_account|amount_received|receiving_currency|amount_paid|payment_currency|payment_format|is_laundering|      index|year|month|day|hour|minute|transaction_received_per_day|transaction_received_per_hour|transaction_received_per_minute|transaction_send_per_day|transaction_send_per_hour|transaction_send_per_minute|minutes_since_last_transaction|unique_to_banks_last_24h|unique_to_accounts_last_24h|\n",
      "+-------------------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+-------------+-----------+----+-----+---+----+------+----------------------------+-----------------------------+-------------------------------+------------------------+-------------------------+---------------------------+------------------------------+------------------------+---------------------------+\n",
      "|2022-09-01 00:19:00|       12|   8000436D0|     12| 8000436D0|        1295.66|              Euro|    1295.66|            Euro|  Reinvestment|            0|     122758|2022|    9|  1|   0|    19|                           4|                            2|                              1|                       2|                        1|                          1|                          -1.0|                    [12]|                [8000436D0]|\n",
      "|2022-09-01 16:02:00|       12|   8000436D0|     12| 8000436D0|          20.95|              Euro|      20.95|            Euro|  Reinvestment|            0|17179889595|2022|    9|  1|  16|     2|                           4|                            1|                              1|                       2|                        1|                          1|                         943.0|                    [12]|                [8000436D0]|\n",
      "|2022-09-02 22:32:00|       12|   8000436D0|  17769| 804900CE0|         293.23|              Euro|     293.23|            Euro|           ACH|            0|34359884758|2022|    9|  2|  22|    32|                           6|                            5|                              1|                       3|                        3|                          1|                        1830.0|                 [17769]|                [804900CE0]|\n",
      "|2022-09-02 22:39:00|       12|   8000436D0|  17769| 804900CE0|        7472.24|              Euro|    7472.24|            Euro|   Credit Card|            0|34359884756|2022|    9|  2|  22|    39|                           6|                            5|                              1|                       3|                        3|                          1|                           7.0|                 [17769]|                [804900CE0]|\n",
      "|2022-09-02 22:54:00|       12|   8000436D0|  17769| 804900CE0|        3296.19|              Euro|    3296.19|            Euro|          Cash|            0|34359884757|2022|    9|  2|  22|    54|                           6|                            5|                              1|                       3|                        3|                          1|                          15.0|                 [17769]|                [804900CE0]|\n",
      "|2022-09-09 15:03:00|       12|   8000436D0|  17769| 804900CE0|        3296.19|              Euro|    3296.19|            Euro|          Cash|            0|85899718162|2022|    9|  9|  15|     3|                           5|                            3|                              1|                       3|                        3|                          1|                        9609.0|                 [17769]|                [804900CE0]|\n",
      "|2022-09-09 15:06:00|       12|   8000436D0|  17769| 804900CE0|        7472.24|              Euro|    7472.24|            Euro|   Credit Card|            0|85899718161|2022|    9|  9|  15|     6|                           5|                            3|                              2|                       3|                        3|                          2|                           3.0|                 [17769]|                [804900CE0]|\n",
      "|2022-09-09 15:06:00|       12|   8000436D0|  17769| 804900CE0|         293.23|              Euro|     293.23|            Euro|           ACH|            0|85899718163|2022|    9|  9|  15|     6|                           5|                            3|                              2|                       3|                        3|                          2|                           0.0|                 [17769]|                [804900CE0]|\n",
      "|2022-09-01 00:14:00|       10|   800043990|     10| 800043990|          23.63|         US Dollar|      23.63|       US Dollar|  Reinvestment|            0|        103|2022|    9|  1|   0|    14|                           3|                            2|                              1|                      24|                        8|                          4|                          -1.0|                    [10]|                [800043990]|\n",
      "|2022-09-01 00:56:00|       10|   800043990|     10| 800043990|        3221.56|         US Dollar|    3221.56|       US Dollar|        Cheque|            0|     327426|2022|    9|  1|   0|    56|                           3|                            2|                              1|                      24|                        8|                          4|                          42.0|                    [10]|                [800043990]|\n",
      "|2022-09-01 04:01:00|       10|   800043990|      1| 8001C76F0|          35.18|         US Dollar|      35.18|       US Dollar|   Credit Card|            0| 8589967608|2022|    9|  1|   4|     1|                           4|                            2|                              1|                      24|                        9|                          4|                         185.0|                 [1, 10]|       [800043990, 8001C...|\n",
      "|2022-09-01 04:11:00|       10|   800043990|      1| 8001C76F0|          39.21|         US Dollar|      39.21|       US Dollar|        Cheque|            0| 8589967607|2022|    9|  1|   4|    11|                           4|                            2|                              1|                      24|                        9|                          3|                          10.0|                 [1, 10]|       [800043990, 8001C...|\n",
      "|2022-09-01 06:42:00|       10|   800043990|     12| 8001F7C90|         183.42|         US Dollar|     183.42|       US Dollar|   Credit Card|            0| 8590051109|2022|    9|  1|   6|    42|                           3|                            4|                              1|                      24|                       15|                          6|                         151.0|             [12, 1, 10]|       [800043990, 8001F...|\n",
      "|2022-09-01 06:51:00|       10|   800043990|     12| 8001F7C90|          41.89|         US Dollar|      41.89|       US Dollar|        Cheque|            0| 8590051108|2022|    9|  1|   6|    51|                           3|                            4|                              2|                      24|                       15|                          5|                           9.0|             [12, 1, 10]|       [800043990, 8001F...|\n",
      "|2022-09-01 10:04:00|       10|   800043990|  11296| 8007A88C0|       292007.7|         US Dollar|   292007.7|       US Dollar|           ACH|            0| 8590168194|2022|    9|  1|  10|     4|                           4|                            4|                              1|                      24|                        8|                          4|                         193.0|      [12, 11296, 1, 10]|       [8007A88C0, 80004...|\n",
      "|2022-09-01 10:13:00|       10|   800043990|  11296| 8007A88C0|       272950.9|         US Dollar|   272950.9|       US Dollar|        Cheque|            0| 8590168193|2022|    9|  1|  10|    13|                           4|                            4|                              1|                      24|                        8|                          4|                           9.0|      [12, 11296, 1, 10]|       [8007A88C0, 80004...|\n",
      "|2022-09-01 13:19:00|       10|   800043990|     10| 800146140|         248.42|         US Dollar|     248.42|       US Dollar|        Cheque|            0| 8590268859|2022|    9|  1|  13|    19|                           7|                            2|                              1|                      24|                        4|                          4|                         186.0|      [12, 11296, 1, 10]|       [8007A88C0, 80014...|\n",
      "|2022-09-01 13:20:00|       10|   800043990|     10| 800146140|         101.13|         US Dollar|     101.13|       US Dollar|          Cash|            0| 8590268860|2022|    9|  1|  13|    20|                           7|                            2|                              2|                      24|                        4|                          3|                           1.0|      [12, 11296, 1, 10]|       [8007A88C0, 80014...|\n",
      "|2022-09-01 14:34:00|       10|   800043990|      1| 80011E2A0|        7960.31|         US Dollar|    7960.31|       US Dollar|   Credit Card|            0| 8590319250|2022|    9|  1|  14|    34|                           4|                            3|                              2|                      24|                        7|                          5|                          74.0|      [12, 11296, 1, 10]|       [8007A88C0, 80014...|\n",
      "|2022-09-01 14:36:00|       10|   800043990|      1| 80011E2A0|       30955.03|         US Dollar|   30955.03|       US Dollar|        Cheque|            0| 8590319249|2022|    9|  1|  14|    36|                           4|                            3|                              1|                      24|                        7|                          4|                           2.0|      [12, 11296, 1, 10]|       [8007A88C0, 80014...|\n",
      "+-------------------+---------+------------+-------+----------+---------------+------------------+-----------+----------------+--------------+-------------+-----------+----+-----+---+----+------+----------------------------+-----------------------------+-------------------------------+------------------------+-------------------------+---------------------------+------------------------------+------------------------+---------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark_df = spark_df.withColumn(\"timestamp_minutes\", F.unix_timestamp(\"timestamp\")/60)\n",
    "\n",
    "# Crea una finestra partizionata per from_account e ordinata per timestamp_minutes\n",
    "# e limita la finestra alle ultime 24 ore (1440 minuti)\n",
    "windowSpec = Window.partitionBy(\"from_account\").orderBy(\"timestamp_minutes\")\\\n",
    "            .rangeBetween(-1440, Window.currentRow)\n",
    "\n",
    "# Calcola i diversi to_bank e to_account univoci all'interno della finestra\n",
    "spark_df = spark_df.withColumn(\"unique_to_banks_last_24h\", F.collect_set(\"to_bank\").over(windowSpec))\n",
    "spark_df = spark_df.withColumn(\"unique_to_accounts_last_24h\", F.collect_set(\"to_account\").over(windowSpec))\n",
    "spark_df = spark_df.drop('timestamp_minutes')\n",
    "\n",
    "# Mostra il risultato\n",
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark_df.drop('unique_to_accounts_last_24h').drop('unique_to_banks_last_24h').drop('timestamp_minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[timestamp: timestamp, from_bank: int, from_account: string, to_bank: int, to_account: string, amount_received: float, receiving_currency: string, amount_paid: float, payment_currency: string, payment_format: string, is_laundering: int, index: bigint, year: int, month: int, day: int, hour: int, minute: int, transaction_received_per_day: bigint, transaction_received_per_hour: bigint, transaction_received_per_minute: bigint, transaction_send_per_day: bigint, transaction_send_per_hour: bigint, transaction_send_per_minute: bigint, minutes_since_last_transaction: double]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark_df.drop('timestamp_minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_columns(df, col1, col2 = None):\n",
    "    unique_columns = set(df.select(col1).orderBy(col1).distinct().rdd.flatMap(lambda x: x).collect())\n",
    "    if(col2 != None):\n",
    "        unique_columns.update(df.select(col2).distinct().rdd.flatMap(lambda x: x).collect())\n",
    "\n",
    "    # Create a dictionary to map accounts to indexes\n",
    "    column_to_index = {column: index for index, column in enumerate(unique_columns)}\n",
    "\n",
    "    # Create a UDF to map accounts to their indexes\n",
    "    from pyspark.sql.functions import udf\n",
    "    from pyspark.sql.types import IntegerType\n",
    "\n",
    "    column_to_index_udf = udf(lambda column: column_to_index[column], IntegerType())\n",
    "\n",
    "    # Add indexed columns to the DataFrame\n",
    "    df_to_return = df.withColumn(f\"{col1}_indexed\", column_to_index_udf(col(col1))).drop(col1).withColumnRenamed(f'{col1}_indexed', col1) \n",
    "    if(col2!=None):\n",
    "        df_to_return = df_to_return.withColumn(f\"{col2}_indexed\", column_to_index_udf(col(col2))).drop(col2).withColumnRenamed(f'{col2}_indexed', col2)\n",
    "    return df_to_return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark_df = label_columns(spark_df, 'from_account', 'to_account')\n",
    "spark_df = label_columns(spark_df, 'receiving_currency', 'payment_currency')\n",
    "spark_df = label_columns(spark_df, 'payment_format')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More correlation among Accounts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find how many times an Account send laund money and not laund money to the same Account.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = spark_df.select('from_account', 'to_account', 'is_laundering')\n",
    "\n",
    "# Raggruppa e conta le occorrenze uniche\n",
    "grouped_df = df_temp.groupBy('from_account', 'to_account').agg(collect_set('is_laundering').alias('unique_values'))\n",
    "\n",
    "# Filtra i risultati con più di una occorrenza\n",
    "filtered_df = grouped_df.filter(col('unique_values').getItem(0) != col('unique_values').getItem(1))\n",
    "\n",
    "# Calcola il numero di occorrenze filtrate per ogni 'from_account'\n",
    "result_df = filtered_df.groupBy('from_account').count().orderBy(col('count').desc())\n",
    "\n",
    "# Mostra i primi 10 risultati\n",
    "result_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[timestamp: bigint, from_bank: int, to_bank: int, amount_received: float, amount_paid: float, is_laundering: int, index: bigint, year: int, month: int, day: int, hour: int, minute: int, transaction_received_per_day: bigint, transaction_received_per_hour: bigint, transaction_received_per_minute: bigint, transaction_send_per_day: bigint, transaction_send_per_hour: bigint, transaction_send_per_minute: bigint, minutes_since_last_transaction: double, avg_previous_amount: double, amount_variation: double, from_account: int, to_account: int, receiving_currency: int, payment_currency: int, payment_format: int]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df = spark_df.withColumn(\"timestamp\",\n",
    "    concat_ws(\"\",\n",
    "        year(\"timestamp\"),\n",
    "        lpad(month(\"timestamp\"), 2, \"0\"),\n",
    "        lpad(dayofmonth(\"timestamp\"), 2, \"0\"),\n",
    "        lpad(hour(\"timestamp\"), 2, \"0\"),\n",
    "        lpad(minute(\"timestamp\"), 2, \"0\")\n",
    "    )\n",
    ")\n",
    "spark_df.withColumn(\"timestamp\", date_format(\"timestamp\", \"yyyyMMddHHmm\").cast(LongType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save first part of analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[timestamp: string, from_bank: int, to_bank: int, amount_received: float, amount_paid: float, is_laundering: int, index: bigint, year: int, month: int, day: int, hour: int, minute: int, transaction_received_per_day: bigint, transaction_received_per_hour: bigint, transaction_received_per_minute: bigint, transaction_send_per_day: bigint, transaction_send_per_hour: bigint, transaction_send_per_minute: bigint, minutes_since_last_transaction: double, avg_previous_amount: double, amount_variation: double, from_account: int, to_account: int, receiving_currency: int, payment_currency: int, payment_format: int]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.coalesce(48).write.parquet('df.parquet', mode='overwrite')\n",
    "spark_df.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('df.parquet2').drop(\"__index_level_0__\")\n",
    "df.persist().count()\n",
    "df.orderBy('index').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using graph frame to work with graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all transactions that are send from A to B with a certain value and from B to C with the same value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = {}\n",
    "values = list(df.select(\"payment_format\").distinct().collect())\n",
    "j = 0\n",
    "for i in range(len(values)):\n",
    "    for k in range(0, len(values)):\n",
    "        combinations[(i,k)] = j\n",
    "        j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_money_send_to_send(df):\n",
    "\n",
    "    # Create GraphFrame\n",
    "    g = GraphFrame(\n",
    "        df.select(F.col(\"from_account\").alias(\"id\")).union(df.select(F.col(\"to_account\").alias(\"id\"))).dropDuplicates(['id']),\n",
    "        df.select(\n",
    "            F.col(\"from_account\").alias(\"src\"),\n",
    "            F.col(\"to_account\").alias(\"dst\"),\n",
    "            F.col(\"index\"),\n",
    "            F.col(\"amount_paid\").alias(\"amount\"),\n",
    "            F.col(\"timestamp\"),\n",
    "            F.col(\"payment_format\"),\n",
    "            F.col(\"is_laundering\")\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Define schema\n",
    "    schema = StructType([\n",
    "        StructField(\"index\", LongType(), False),\n",
    "        StructField(\"timestamp\", DoubleType(), False),\n",
    "        StructField(\"from\", IntegerType(), False),\n",
    "        StructField(\"to\", IntegerType(), False),\n",
    "        StructField(\"payment_format\", IntegerType(), False),\n",
    "        StructField(\"is_laundering\", IntegerType(), False),\n",
    "        StructField(\"payment_payment\", IntegerType(), False)\n",
    "    ])\n",
    "    \n",
    "    # Filter graph\n",
    "    motif = \"(a)-[c1]->(b); (b)-[c2]->(c)\"\n",
    "    graph = g.find(motif).filter(\"a != b and b != c and c1.amount == c2.amount and c1.timestamp < c2.timestamp\").distinct()\n",
    "    pattern = np.array(graph.select('c1', 'c2').collect()).squeeze()\n",
    "\n",
    "    total_rows = []\n",
    "    for row in pattern:\n",
    "        rows = [[int(r[2]), float(r[4]), int(r[0]), int(r[1]), int(r[5]), int(r[6]), combinations[(int(row[0][5]), int(row[1][5]))]] for r in (row if isinstance(row[1], np.ndarray) else [row])]\n",
    "        total_rows.extend(rows)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    temp_df = spark.createDataFrame(total_rows, schema).coalesce(48).dropDuplicates(['index'])\n",
    "\n",
    "    # Join DataFrames\n",
    "    df = df.join(\n",
    "        broadcast(temp_df.select(\"index\", \"payment_payment\").withColumnRenamed(\"payment_payment\", \"payment_payment_B\")),\n",
    "        on=\"index\",\n",
    "        how=\"left\"\n",
    "    ).withColumn(\n",
    "        \"payment_payment\", \n",
    "        F.when(F.col(\"payment_payment_B\").isNotNull(), F.col(\"payment_payment_B\")).otherwise(-1)\n",
    "    ).drop(\"payment_payment_B\").coalesce(48).write.parquet(os.path.join(spark_partial_results_folder, 'partial_df'), mode='overwrite')\n",
    "    \n",
    "    return spark.read.parquet(os.path.join(spark_partial_results_folder, 'partial_df')).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_money_send_to_send(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.parquet('df.parquet2', mode='overwrite')\n",
    "df.unpersist()\n",
    "df = spark.read.parquet('df.parquet2')\n",
    "df.cache().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find circular patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cycles(df):\n",
    "\n",
    "    schema = StructType([\n",
    "        StructField(\"index\", LongType(), False),\n",
    "        StructField(\"timestamp\", FloatType(), False),\n",
    "        StructField(\"from\", IntegerType(), False),\n",
    "        StructField(\"to\", IntegerType(), False),\n",
    "        StructField(\"payment_format\", IntegerType(), False),\n",
    "        StructField(\"is_laundering\", IntegerType(), False),\n",
    "        StructField(\"hop_2\", IntegerType(), False),\n",
    "        StructField(\"hop_3\", IntegerType(), False),\n",
    "        StructField(\"hop_4\", IntegerType(), False),\n",
    "        StructField(\"hop_5\", IntegerType(), False),\n",
    "        StructField(\"hop_6\", IntegerType(), False),\n",
    "        StructField(\"hop_7\", IntegerType(), False),\n",
    "        StructField(\"hop_8\", IntegerType(), False),\n",
    "        StructField(\"hop_9\", IntegerType(), False),\n",
    "        StructField(\"hop_10\", IntegerType(), False),\n",
    "        StructField(\"hop_11\", IntegerType(), False),\n",
    "        StructField(\"hop_12\", IntegerType(), False),\n",
    "        StructField(\"hop_13\", IntegerType(), False),\n",
    "    ])\n",
    "\n",
    "\n",
    "    all_df = []\n",
    "    filtered_spark = df.filter(F.col(\"payment_currency\") == F.col(\"receiving_currency\"))\n",
    "    filtered_spark.cache()\n",
    "    #payment_formats = filtered_spark.select(\"payment_format\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "    for k in range(1):\n",
    "        verteces = filtered_spark.filter(F.col(\"payment_format\") == 2).select(F.col(\"from_account\").alias(\"id\")).union(filtered_spark.filter(F.col(\"payment_format\") == 2).select(F.col(\"to_account\").alias(\"id\"))).distinct()\n",
    "        edges = filtered_spark.filter(F.col(\"payment_format\") == 2).select(F.col(\"from_account\").alias(\"src\"), F.col(\"to_account\").alias(\"dst\"), F.col(\"index\"), F.col(\"amount_paid\").alias(\"amount\"), F.col(\"timestamp\"), F.col(\"payment_format\"), F.col(\"is_laundering\"))\n",
    "        g = GraphFrame(verteces, edges)\n",
    "        g = g.dropIsolatedVertices()\n",
    "        g.cache()\n",
    "        for hop in tqdm.tqdm(range(2,14)):\n",
    "            \n",
    "            motif = \"\"\n",
    "\n",
    "            for i in range(hop):\n",
    "                motif += \"(n\" + str(i) + \")-[c\" + str(i+1) + \"]->(n\" + str((i+1) % hop) + \"); \"\n",
    "            motif = motif.strip(\"; \")\n",
    "\n",
    "            filter_string = \"\"\n",
    "            for i in range(hop):\n",
    "                for j in range(i, hop-1):\n",
    "                    filter_string += \"n{} != n{}\".format(i, j+1)\n",
    "                    if i+1 < hop-1:\n",
    "                        filter_string += \" and \"\n",
    "            filter_string += \" and \"\n",
    "            for j in range(1,hop):\n",
    "                    filter_string += \"c{}.timestamp < c{}.timestamp\".format(j, j+1)\n",
    "                    if(j+1 < hop):\n",
    "                        filter_string += \" and \"    \n",
    "            select_col = []\n",
    "            for i in range(hop):\n",
    "                select_col.append(\"c{}\".format(i+1))\n",
    "            pattern_g = g.find(motif).filter(filter_string)\n",
    "            pattern = np.array(pattern_g.select(*select_col).collect()).squeeze()\n",
    "            total_rows = []\n",
    "\n",
    "            for row in pattern:\n",
    "                if isinstance(row[1], np.ndarray):\n",
    "                    for r in row:\n",
    "                        #index | timestamp | from | to | payment_format | is_laundering | hop\n",
    "                        total_rows.append([int(r[2]), float(r[4]), int(r[0]), int(r[1]), int(r[5]), int(r[6]), hop])\n",
    "                else:\n",
    "                    total_rows.append([int(row[2]), float(row[4]), int(row[0]), int(row[1]), int(row[5]), int(row[6]), hop])\n",
    "            \n",
    "            dataframe = pd.DataFrame(total_rows, columns=['index', 'timestamp', 'from', 'to', 'payment_format', 'is_laundering', 'hop'])\n",
    "\n",
    "            all_df.append(dataframe.drop_duplicates())\n",
    "        g.unpersist()\n",
    "        filtered_spark.unpersist()\n",
    " \n",
    "    merged_df = pd.concat(all_df, ignore_index=True)\n",
    "    one_hot_encoded_df = pd.get_dummies(merged_df, columns=['hop'], prefix='hop')\n",
    "\n",
    "    columns_to_add = [f\"hop_{i}\" for i in range(2, 14)]\n",
    "    for col in columns_to_add:\n",
    "        if col not in one_hot_encoded_df.columns:\n",
    "            one_hot_encoded_df[col] = False\n",
    "\n",
    "    grouped_df = one_hot_encoded_df.groupby('index').agg({\n",
    "        'timestamp': 'first',\n",
    "        'from': 'first',\n",
    "        'to': 'first',\n",
    "        'payment_format': 'first',\n",
    "        'is_laundering': 'first',\n",
    "        **{col: 'any' for col in columns_to_add}\n",
    "    }).reset_index()\n",
    "   \n",
    "    columns_to_encode = ['hop_2', 'hop_3', 'hop_4', 'hop_5', 'hop_6', 'hop_7', 'hop_8', 'hop_9', 'hop_10', 'hop_11', 'hop_12', 'hop_13']\n",
    "    grouped_df[columns_to_encode] = grouped_df[columns_to_encode].fillna(False, inplace=False).astype(int)\n",
    "    \n",
    "    temp_df = spark.createDataFrame(grouped_df, schema)\n",
    "\n",
    "    temp_df = temp_df.dropDuplicates(['index'])\n",
    "\n",
    "    # Step 1: Seleziona solo le colonne necessarie da temp_df e rinomina le colonne\n",
    "    temp_df_selected = temp_df.select(\n",
    "        \"index\",\n",
    "        \"hop_2\", \"hop_3\", \"hop_4\", \"hop_5\", \"hop_6\",\n",
    "        \"hop_7\", \"hop_8\", \"hop_9\", \"hop_10\", \"hop_11\",\n",
    "        \"hop_12\", \"hop_13\"\n",
    "    ).withColumnRenamed(\"hop_2\", \"hop_2_B\").withColumnRenamed(\"hop_3\", \"hop_3_B\").withColumnRenamed(\"hop_4\", \"hop_4_B\").withColumnRenamed(\"hop_5\", \"hop_5_B\").withColumnRenamed(\"hop_6\", \"hop_6_B\").withColumnRenamed(\"hop_7\", \"hop_7_B\").withColumnRenamed(\"hop_8\", \"hop_8_B\").withColumnRenamed(\"hop_9\", \"hop_9_B\").withColumnRenamed(\"hop_10\", \"hop_10_B\").withColumnRenamed(\"hop_11\", \"hop_11_B\").withColumnRenamed(\"hop_12\", \"hop_12_B\").withColumnRenamed(\"hop_13\", \"hop_13_B\")\n",
    "\n",
    "    # Step 2: Esegui una left join tra df e temp_df_selected, usando l'indice come chiave di join\n",
    "    joined_df = df.join(temp_df_selected, on=\"index\", how=\"left\")\n",
    "\n",
    "    # Step 3: Usa la funzione when per assegnare il valore corrispondente da hop_i_B se presente, altrimenti imposta il valore a 0\n",
    "    for i in range(2, 14):\n",
    "        joined_df = joined_df.withColumn(\n",
    "            f\"hop_{i}\", \n",
    "            F.when(F.col(f\"hop_{i}_B\").isNotNull(), F.col(f\"hop_{i}_B\")).otherwise(0)\n",
    "        )\n",
    "\n",
    "    # Step 4: Rimuovi le colonne aggiunte da temp_df_selected\n",
    "    joined_df = joined_df.drop(*[f\"hop_{i}_B\" for i in range(2, 14)])\n",
    "    \n",
    "    joined_df.write.parquet(os.path.join(spark_partial_results_folder, 'partial_df'), mode='overwrite')\n",
    "    # Il risultato finale è il dataframe df con le colonne hop_2 a hop_13 aggiunte e i valori 0 dove necessario\n",
    "    df.unpersist()\n",
    "    \n",
    "    \n",
    "    return spark.read.parquet(os.path.join(spark_partial_results_folder, 'partial_df')).repartition(48).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = find_cycles(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.parquet('df.parquet2', mode='overwrite')\n",
    "df.unpersist()\n",
    "df = spark.read.parquet('df.parquet2')\n",
    "df.cache().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find fan in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_fanin(g: GraphFrame):\n",
    "    motif = \"(a)-[c1]->(b); (c)-[c2]->(b)\"\n",
    "    filter_motif = \"(abs(c1.timestamp - c2.timestamp)) <= 40000 and c1.index != c2.index and c1.payment_currency == c2.payment_currency\"#and c1.payment_format == c2.payment_format\"\n",
    "    pattern = g.find(motif).filter(filter_motif).select(\"c1\", \"c2\")\n",
    "    pattern.coalesce(48)\n",
    "    fan_in_trans = pattern.groupBy(col(\"c1\")).agg(count(\"*\").alias(\"fan_in_degree\")).select(col(\"c1\").alias(\"transaction\"), col(\"fan_in_degree\"))\n",
    "    \n",
    "    \n",
    "    return fan_in_trans.distinct()\n",
    "\n",
    "def add_fan_in(df):\n",
    "    filtered_spark = df.filter(col(\"payment_currency\") == col(\"receiving_currency\"))\n",
    "    filtered_spark.cache()\n",
    "    payment_formats = filtered_spark.select(\"payment_format\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "    total_fan_in = None\n",
    "\n",
    "    for payment_format in payment_formats:\n",
    "        filtered_by_format = filtered_spark.filter(col(\"payment_format\") == payment_format)\n",
    "        verteces = (\n",
    "            filtered_by_format.select(col(\"from_account\").alias(\"id\"))\n",
    "            .union(filtered_by_format.select(col(\"to_account\").alias(\"id\")))\n",
    "            .distinct()\n",
    "        )\n",
    "        edges = (\n",
    "            filtered_by_format.select(\n",
    "                col(\"from_account\").alias(\"src\"),\n",
    "                col(\"to_account\").alias(\"dst\"),\n",
    "                col(\"index\"),\n",
    "                col(\"timestamp\"),\n",
    "                col(\"payment_currency\"),\n",
    "                col(\"payment_format\"),\n",
    "                col(\"is_laundering\")\n",
    "                \n",
    "            )\n",
    "        )\n",
    "        g = GraphFrame(verteces, edges)\n",
    "        find_fanin(g).coalesce(48).write.parquet(os.path.join(spark_partial_results_folder, f'fanin_{payment_format}'), mode='overwrite')\n",
    "        \"\"\"all_fan_ins = []\n",
    "        if total_fan_in is None:\n",
    "            find_fanin(g).repartition(48).write.parquet(os.path.join(spark_partial_results_folder, f'_{payment_format}'))\n",
    "            fan_in = find_fanin(g)\n",
    "            total_fan_in = fan_in\n",
    "            all_fan_ins.append(fan_in)\n",
    "        else:\n",
    "            fan_in = find_fanin(g)\n",
    "            total_fan_in = total_fan_in.union(fan_in)  \n",
    "            all_fan_ins.append(fan_in)\n",
    "            total_fan_in = total_fan_in.coalesce(48)\"\"\"\n",
    "        \n",
    "    total_fan_in = None\n",
    "    for payment_format in payment_formats:\n",
    "        if total_fan_in is None: \n",
    "            total_fan_in = spark.read.parquet(os.path.join(spark_partial_results_folder, f'fanin_{payment_format}'))\n",
    "        else:\n",
    "            total_fan_in.union(spark.read.parquet(os.path.join(spark_partial_results_folder, f'fanin_{payment_format}')))\n",
    "\n",
    "    temp_df = total_fan_in.select(\"transaction.*\", \"fan_in_degree\")\n",
    "   \n",
    "\n",
    "    joined_df = df.join(broadcast(temp_df.select(\"index\", col(\"fan_in_degree\").alias(\"fan_in_degree_B\"))), on=\"index\", how=\"left\")\n",
    "    \n",
    "\n",
    "    # Aggiungi la colonna \"payment_payment\" a dfA, usando il valore corrispondente da dfB se presente, altrimenti imposta -1\n",
    "    df = joined_df.withColumn(\"fan_in_degree\", F.when(F.col(\"fan_in_degree_B\").isNotNull(), F.col(\"fan_in_degree_B\")).otherwise(0)).drop(\"fan_in_degree_B\")\n",
    "    df.coalesce(48).write.parquet(os.path.join(spark_partial_results_folder, 'partial_df'), mode='overwrite')\n",
    "    for payment_format in payment_formats:\n",
    "        shutil.rmtree(os.path.join(spark_partial_results_folder, f'fanin_{payment_format}'))\n",
    "\n",
    "        \n",
    "    filtered_spark.unpersist()\n",
    "    df.unpersist()    \n",
    "    return spark.read.parquet(os.path.join(spark_partial_results_folder, 'partial_df')).repartition(48).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_fan_in(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.parquet('df.parquet2', mode='overwrite')\n",
    "df.unpersist()\n",
    "df = spark.read.parquet('df.parquet2')\n",
    "df.cache().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find fan out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_fanout(g: GraphFrame):\n",
    "    motif = \"(a)-[c1]->(b); (a)-[c2]->(c)\"\n",
    "    filter_motif = \"(abs(c1.timestamp - c2.timestamp)) <= 40000 and c1.index != c2.index\"\n",
    "    pattern = g.find(motif).filter(filter_motif).select(\"c1\", \"c2\")\n",
    "    pattern.coalesce(48)\n",
    "    return pattern.groupBy(F.col(\"c1\")).agg(F.count(\"*\").alias(\"fan_out_degree\")).select(F.col(\"c1\").alias(\"transaction\"), F.col(\"fan_out_degree\")).distinct()\n",
    "\n",
    "def add_fatn_out(df):\n",
    "    filtered_spark = df.filter(F.col(\"payment_currency\") == F.col(\"receiving_currency\")).cache()\n",
    "    \n",
    "    payment_format = 2  # Assuming you wanted to only process for payment_format = 2\n",
    "    print(f\"Find fan out payment_format: {payment_format}\")\n",
    "    \n",
    "    filtered_by_format = filtered_spark.filter(F.col(\"payment_format\") == payment_format).cache()\n",
    "    \n",
    "    verteces = (\n",
    "        filtered_by_format.select(F.col(\"from_account\").alias(\"id\"))\n",
    "        .union(filtered_by_format.select(F.col(\"to_account\").alias(\"id\")))\n",
    "        .distinct()\n",
    "    )\n",
    "    edges = filtered_by_format.select(\n",
    "        F.col(\"from_account\").alias(\"src\"),\n",
    "        F.col(\"to_account\").alias(\"dst\"),\n",
    "        F.col(\"index\"),\n",
    "        F.col(\"timestamp\"),\n",
    "        F.col(\"payment_format\"),\n",
    "        F.col(\"is_laundering\")\n",
    "    ).coalesce(48)\n",
    "    \n",
    "    g = GraphFrame(verteces, edges)\n",
    "    find_fanout(g).coalesce(48).write.parquet(os.path.join(spark_partial_results_folder, f'fanout_{payment_format}'), mode='overwrite')\n",
    "    \n",
    "    g.unpersist()\n",
    "    filtered_by_format.unpersist() \n",
    "\n",
    "    total_fan_out = spark.read.parquet(os.path.join(spark_partial_results_folder, f'fanout_{payment_format}'))\n",
    "    temp_df = total_fan_out.select(\"transaction.*\", \"fan_out_degree\")\n",
    "    joined_df = df.join(broadcast(temp_df.select(\"index\", col(\"fan_out_degree\").alias(\"fan_out_degree_B\"))), on=\"index\", how=\"left\")\n",
    "    df = joined_df.withColumn(\"fan_out_degree\", F.when(F.col(\"fan_out_degree_B\").isNotNull(), F.col(\"fan_out_degree_B\")).otherwise(0)).drop(\"fan_out_degree_B\")\n",
    "    \n",
    "    df.coalesce(48).write.parquet(os.path.join(spark_partial_results_folder, 'partial_df'), mode='overwrite')\n",
    "    shutil.rmtree(os.path.join(spark_partial_results_folder, f'fanout_{payment_format}'))\n",
    "    df.unpersist()\n",
    "    return spark.read.parquet(os.path.join(spark_partial_results_folder, 'partial_df')).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_fanout(g: GraphFrame):\n",
    "    motif = \"(a)-[c1]->(b); (a)-[c2]->(c)\"\n",
    "    filter_motif = \"(abs(c1.timestamp - c2.timestamp)) <= 40000 and c1.index != c2.index\"\n",
    "    pattern = g.find(motif).filter(filter_motif).select(\"c1\", \"c2\")\n",
    "    pattern.coalesce(48)\n",
    "    return pattern.groupBy(F.col(\"c1\")).agg(F.count(\"*\").alias(\"fan_out_degree\")).select(F.col(\"c1\").alias(\"transaction\"), F.col(\"fan_out_degree\")).dropDuplicates(['transaction'])\n",
    "\n",
    "\n",
    "def add_fan_out(df):\n",
    "    filtered_spark = df.filter(col(\"payment_currency\") == col(\"receiving_currency\"))\n",
    "    filtered_spark.cache()\n",
    "    payment_formats = filtered_spark.select(\"payment_format\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "    for payment_format in payment_formats:\n",
    "        filtered_by_format = filtered_spark.filter(col(\"payment_format\") == payment_format)\n",
    "        verteces = (\n",
    "            filtered_by_format.select(col(\"from_account\").alias(\"id\"))\n",
    "            .union(filtered_by_format.select(col(\"to_account\").alias(\"id\")))\n",
    "            .distinct()\n",
    "        )\n",
    "        edges = filtered_by_format.select(\n",
    "            F.col(\"from_account\").alias(\"src\"),\n",
    "            F.col(\"to_account\").alias(\"dst\"),\n",
    "            F.col(\"index\"),\n",
    "            F.col(\"timestamp\"),\n",
    "            F.col(\"payment_format\"),\n",
    "            F.col(\"is_laundering\")\n",
    "        ).coalesce(48)\n",
    "        g = GraphFrame(verteces, edges)\n",
    "        find_fanout(g).coalesce(48).write.parquet(os.path.join(spark_partial_results_folder, f'fanout_{payment_format}'), mode='overwrite')\n",
    "        \n",
    "        \n",
    "    total_fan_out = None\n",
    "    for payment_format in payment_formats:\n",
    "        if total_fan_out is None: \n",
    "            total_fan_out = spark.read.parquet(os.path.join(spark_partial_results_folder, f'fanout_{payment_format}'))\n",
    "        else:\n",
    "            total_fan_out.union(spark.read.parquet(os.path.join(spark_partial_results_folder, f'fanout_{payment_format}')))\n",
    "\n",
    "    temp_df = total_fan_out.select(\"transaction.*\", \"fan_out_degree\")\n",
    "   \n",
    "\n",
    "    joined_df = df.join(broadcast(temp_df.select(\"index\", col(\"fan_out_degree\").alias(\"fan_out_degree_B\"))), on=\"index\", how=\"left\")\n",
    "    \n",
    "\n",
    "    # Aggiungi la colonna \"payment_payment\" a dfA, usando il valore corrispondente da dfB se presente, altrimenti imposta -1\n",
    "    joined_df = joined_df.withColumn(\"fan_out_degree\", F.when(F.col(\"fan_out_degree_B\").isNotNull(), F.col(\"fan_out_degree_B\")).otherwise(0)).drop(\"fan_out_degree_B\")\n",
    "    joined_df.coalesce(48).write.parquet(os.path.join(spark_partial_results_folder, 'partial_df'), mode='overwrite')\n",
    "    for payment_format in payment_formats:\n",
    "        shutil.rmtree(os.path.join(spark_partial_results_folder, f'fanout_{payment_format}'))\n",
    "\n",
    "        \n",
    "    filtered_spark.unpersist()\n",
    "    df.unpersist()    \n",
    "    return spark.read.parquet(os.path.join(spark_partial_results_folder, 'partial_df')).repartition(48).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_fan_out(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.parquet('df.parquet2', mode='overwrite')\n",
    "df.unpersist()\n",
    "df = spark.read.parquet('df.parquet2')\n",
    "df.cache().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display correlation matrix for fraudolent transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/10 14:41:40 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 56425873 ms exceeds timeout 120000 ms\n",
      "23/08/10 14:41:40 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "23/08/10 14:41:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:41:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:41:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:41:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:42:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:42:01 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:42:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:42:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:42:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:42:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:42:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:42:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:42:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:42:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:42:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:42:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:43:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:43:01 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:43:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:43:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:43:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:43:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:43:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:43:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:43:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:43:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:43:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/08/10 14:43:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/08/10 14:44:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:44:01 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:44:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/08/10 14:44:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/08/10 14:44:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:44:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:44:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:44:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:44:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:44:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:44:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/08/10 14:44:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/08/10 14:45:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:45:01 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:45:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:45:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:45:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:45:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:45:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:45:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:45:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:45:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:45:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:45:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:46:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:46:01 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:46:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:46:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:46:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:46:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:46:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:46:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:46:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:46:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:46:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:46:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:47:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:47:01 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:47:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:47:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:47:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:47:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:47:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:47:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:47:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:47:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:47:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:47:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:48:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/08/10 14:48:01 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/08/10 14:48:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:48:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:48:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:48:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:48:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:48:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:48:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:48:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:48:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:48:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:49:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:49:01 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:49:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:49:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:49:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:49:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:49:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:49:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:49:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:49:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:49:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:49:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:50:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:50:01 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:50:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:50:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:50:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:50:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:50:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:50:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:50:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:50:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:50:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/08/10 14:50:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/08/10 14:51:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/08/10 14:51:01 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/08/10 14:51:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/08/10 14:51:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/08/10 14:51:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:51:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:51:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:51:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:113)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:112)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:548)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:547)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:585)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:45883\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/08/10 14:51:31 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet('df.parquet').drop('year').drop('month').drop('from_bank').drop('to_bank').drop('index').drop('amount_received').drop('amount_paid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowSpec = Window.partitionBy(\"from_account\", \"to_account\").orderBy(\"timestamp\").rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "\n",
    "# Calcola la ricorrenza delle transazioni\n",
    "df = df.withColumn(\"transaction_recurrence\", F.count(\"timestamp\").over(windowSpec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"timestamp_minutes\", F.unix_timestamp(\"timestamp\")/60)\n",
    "\n",
    "# Crea una finestra partizionata per from_account e ordinata per timestamp_minutes\n",
    "# e limita la finestra alle ultime 24 ore (1440 minuti)\n",
    "windowSpec = Window.partitionBy(\"from_account\").orderBy(\"timestamp_minutes\")\\\n",
    "            .rangeBetween(-1440, Window.currentRow)\n",
    "\n",
    "# Calcola i diversi payment_format utilizzati all'interno della finestra temporale\n",
    "df = df.withColumn(\"unique_payment_formats_last_day\", F.collect_set(\"payment_format\").over(windowSpec))\n",
    "\n",
    "# Calcola il numero di metodi di pagamento unici utilizzati\n",
    "df = df.withColumn(\"num_unique_payment_formats_last_day\", F.size(\"unique_payment_formats_last_day\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea una finestra partizionata per from_account e ordinata per timestamp_minutes\n",
    "# e limita la finestra alle ultime 24 ore (1440 minuti)\n",
    "windowSpec = Window.partitionBy(\"from_account\").orderBy(\"timestamp_minutes\")\\\n",
    "            .rangeBetween(-1440, Window.currentRow)\n",
    "\n",
    "# Calcola i diversi payment_format utilizzati all'interno della finestra temporale\n",
    "df = df.withColumn(\"unique_payment_currency_last_day\", F.collect_set(\"payment_currency\").over(windowSpec))\n",
    "\n",
    "# Calcola il numero di metodi di pagamento unici utilizzati\n",
    "df = df.withColumn(\"num_unique_payment_currency_last_day\", F.size(\"unique_payment_currency_last_day\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('timestamp_minutes').drop('unique_payment_formats_last_day').drop('unique_payment_currency_last_day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:===================================================>    (12 + 1) / 13]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---+----+------+----------------------------+-----------------------------+-------------------------------+------------------------+-------------------------+---------------------------+------------------------------+-------------------+-------------------+------------------+----------------+--------------+----------------------+-------------------------------+-----------------------------------+\n",
      "|is_laundering|day|hour|minute|transaction_received_per_day|transaction_received_per_hour|transaction_received_per_minute|transaction_send_per_day|transaction_send_per_hour|transaction_send_per_minute|minutes_since_last_transaction|avg_previous_amount|   amount_variation|receiving_currency|payment_currency|payment_format|transaction_recurrence|unique_payment_formats_last_24h|num_unique_payment_formats_last_24h|\n",
      "+-------------+---+----+------+----------------------------+-----------------------------+-------------------------------+------------------------+-------------------------+---------------------------+------------------------------+-------------------+-------------------+------------------+----------------+--------------+----------------------+-------------------------------+-----------------------------------+\n",
      "|            0|  1|  13|    29|                           1|                            1|                              1|                       1|                        1|                          1|                          -1.0|                0.0|      5169.83984375|                11|              11|             5|                     1|                            [5]|                                  1|\n",
      "|            0|  1|   0|    17|                           2|                            2|                              2|                       2|                        2|                          2|                          -1.0|                0.0|       35491.359375|                 0|               0|             5|                     1|                            [5]|                                  1|\n",
      "|            0|  1|   0|    17|                           2|                            2|                              2|                       2|                        2|                          2|                           0.0|       35491.359375| -35483.32937526703|                 0|               0|             5|                     2|                            [5]|                                  1|\n",
      "|            0|  6|  21|    57|                          20|                           24|                              3|                       1|                        1|                          1|                        8515.0| 14.630000114440918|  2225.900029182434|                11|              11|             2|                     1|                         [5, 2]|                                  2|\n",
      "|            0|  1|   0|     2|                           1|                            1|                              1|                       1|                        1|                          1|                          -1.0|                0.0| 14.630000114440918|                11|              11|             5|                     1|                         [5, 2]|                                  2|\n",
      "|            0|  1|   0|    10|                           7|                            6|                              1|                       3|                        1|                          1|                          -1.0|                0.0| 10.760000228881836|                11|              11|             5|                     1|                      [5, 3, 4]|                                  3|\n",
      "|            0|  1|  20|    39|                           7|                            1|                              1|                       3|                        1|                          1|                        1003.0|  1906.444941520691|  401958.2113084793|                11|              11|             5|                     2|                      [5, 3, 4]|                                  3|\n",
      "|            0|  2|   2|    48|                           3|                            2|                              1|                       3|                        2|                          1|                         369.0| 135892.51537768045|-117790.38451830545|                11|              11|             3|                     1|                      [5, 3, 4]|                                  3|\n",
      "|            0|  2|   2|    51|                           3|                            2|                              2|                       3|                        2|                          2|                           3.0|  106444.9192481041|-100704.09942388535|                11|              11|             4|                     2|                      [5, 3, 4]|                                  3|\n",
      "|            0|  9|  16|    51|                           3|                            3|                              2|                       3|                        2|                          2|                        1381.0|  45053.11462306976| -39312.29479885101|                11|              11|             4|                     3|                      [5, 3, 4]|                                  3|\n",
      "|            0|  9|  16|    55|                           3|                            3|                              1|                       3|                        2|                          1|                           4.0|  41479.26964135603|-23377.138781981033|                11|              11|             3|                     4|                      [5, 3, 4]|                                  3|\n",
      "|            0|  1|   3|    56|                           2|                            1|                              1|                       3|                        1|                          1|                         226.0| 10.760000228881836|  3791.369882583618|                11|              11|             4|                     1|                      [5, 3, 4]|                                  3|\n",
      "|            0|  2|  21|    44|                           2|                            1|                              1|                       3|                        1|                          1|                        1133.0|  86304.09936332703| -82501.96948051453|                11|              11|             4|                     2|                      [5, 3, 4]|                                  3|\n",
      "|            0|  5|   9|    13|                           1|                            1|                              1|                       1|                        1|                          1|                        3569.0|   72553.7711165746|  -68751.6412337621|                11|              11|             4|                     3|                      [5, 3, 4]|                                  3|\n",
      "|            0|  6|   6|    21|                           1|                            1|                              1|                       1|                        1|                          1|                        1268.0|  62732.10808318002| -58929.97820036752|                11|              11|             4|                     4|                      [5, 3, 4]|                                  3|\n",
      "|            0|  7|  19|     3|                           1|                            1|                              1|                       1|                        1|                          1|                        2202.0|  55365.86080813408| -51563.73092532158|                11|              11|             4|                     5|                      [5, 3, 4]|                                  3|\n",
      "|            0|  8|  17|    50|                           1|                            1|                              1|                       1|                        1|                          1|                        1367.0|  49636.55737198723| -45834.42748917473|                11|              11|             4|                     6|                      [5, 3, 4]|                                  3|\n",
      "|            0|  9|  22|    45|                           2|                            1|                              2|                       3|                        1|                          1|                         350.0|  39531.17474285761| -35729.04486004511|                11|              11|             4|                     7|                      [5, 3, 4]|                                  3|\n",
      "|            0|  1|  15|     8|                           1|                            1|                              1|                       1|                        1|                          1|                          -1.0|                0.0|   6137.77001953125|                 0|               0|             5|                     1|                            [5]|                                  1|\n",
      "|            0|  1|   5|    47|                           6|                            4|                              1|                       8|                        4|                          1|                          34.0| 2.8494410652977726| -2.205480052934339|                 3|               3|             0|                     1|                            [0]|                                  1|\n",
      "+-------------+---+----+------+----------------------------+-----------------------------+-------------------------------+------------------------+-------------------------+---------------------------+------------------------------+-------------------+-------------------+------------------+----------------+--------------+----------------------+-------------------------------+-----------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Seleziona le colonne numeriche su cui calcolare la correlazione\n",
    "numeric_columns = ['from_bank', 'to_bank', 'from_account', 'to_account','receiving_currency','payment_currency','payment_format', 'amount_received', 'amount_paid',  'day', 'hour', 'minute', 'transaction_received_per_day',  'transaction_received_per_hour',  'transaction_received_per_minute', 'transaction_send_per_day',  'transaction_send_per_hour',  'transaction_send_per_minute','payment_payment','hop_2', 'hop_3', 'hop_4', 'hop_5', 'hop_6', 'hop_7', 'hop_8', 'hop_9', 'hop_10', 'hop_11', 'hop_12', 'fan_in_degree', 'fan_out_degree', 'is_laundering']\n",
    "\n",
    "# Crea un VectorAssembler per creare una singola colonna \"features\"\n",
    "assembler = VectorAssembler(inputCols=df.columns, outputCol=\"features\")\n",
    "assembled_df = assembler.transform(df).select(\"features\")\n",
    "\n",
    "\n",
    "# Calcola la matrice di correlazione per entrambi i casi\n",
    "laundering_corr_matrix = df.select(df.columns).toPandas().corr()\n",
    "\n",
    "# create subplots\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(22, 8))\n",
    "\n",
    "# plot the first correlation matrix heatmap\n",
    "sns.heatmap(laundering_corr_matrix, cmap='coolwarm', annot=False, ax=ax)\n",
    "ax.set_title('Correlation matrix')\n",
    "\n",
    "# display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Load and order the DataFrame\n",
    "df = spark.read.parquet('df.parquet')\n",
    "ordered_df = df.orderBy(\"timestamp\")\n",
    "\n",
    "# Calculate row counts for splits\n",
    "total_rows = ordered_df.count()\n",
    "train_rows, validation_rows = int(total_rows * 0.6), int(total_rows * 0.2)\n",
    "test_rows = total_rows - train_rows - validation_rows\n",
    "\n",
    "# Add a dummy partition and assign row numbers based on ordered timestamps\n",
    "w = Window.partitionBy(lit(1)).orderBy(\"timestamp\")\n",
    "ordered_df = ordered_df.withColumn(\"row_number\", F.row_number().over(w))\n",
    "\n",
    "# Split and repartition the DataFrame into train, validation, and test sets based on row numbers\n",
    "train_df = ordered_df.filter(col(\"row_number\") <= train_rows).drop(\"row_number\", \"dummy_partition\").repartition(48)\n",
    "validation_df = ordered_df.filter(col(\"row_number\").between(train_rows + 1, train_rows + validation_rows)).drop(\"row_number\", \"dummy_partition\").repartition(48)\n",
    "test_df = ordered_df.filter(col(\"row_number\") > train_rows + validation_rows).drop(\"row_number\", \"dummy_partition\").repartition(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_reload(df, name):\n",
    "    df.repartition(48).write.parquet(f'./preprocessed_data/df.{name}', mode='overwrite')\n",
    "    df.unpersist()\n",
    "    df = spark.read.parquet(f'./preprocessed_data/df.{name}')\n",
    "    df.cache()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df(df, name):\n",
    "    print(\"Adding transaction received...\")\n",
    "    df = add_trans_received(df)\n",
    "    print(\"Adding transaction send...\")\n",
    "    df = add_trans_send(df)\n",
    "    print(\"Adding money send to send...\")\n",
    "    df = add_money_send_to_send(df)\n",
    "    #print(\"Adding cycles...\")\n",
    "    #df = find_cycles(df)\n",
    "    print(\"Adding fan-in...\")\n",
    "    df = add_fan_in(df)\n",
    "    print(\"Adding fan-out...\")\n",
    "    df = add_fan_out(df)\n",
    "    shutil.move(os.path.join(spark_partial_results_folder, 'partial_df'), os.path.join('./to_preprocess', f'df.{name}'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding transaction received...\n",
      "Adding transaction send...\n",
      "Adding money send to send...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/09 18:53:38 WARN CacheManager: Asked to cache already cached data.        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding fan-in...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding fan-out...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/09 18:57:32 WARN CacheManager: Asked to cache already cached data.        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding transaction received...\n",
      "Adding transaction send...\n",
      "Adding money send to send...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/09 18:57:51 WARN CacheManager: Asked to cache already cached data.        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding fan-in...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding fan-out...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/09 18:58:57 WARN CacheManager: Asked to cache already cached data.        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding transaction received...\n",
      "Adding transaction send...\n",
      "Adding money send to send...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/09 18:59:16 WARN CacheManager: Asked to cache already cached data.        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding fan-in...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding fan-out...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/09 19:00:18 WARN CacheManager: Asked to cache already cached data.        \n"
     ]
    }
   ],
   "source": [
    "save_df(train_df, 'train')\n",
    "save_df(validation_df, 'validation')\n",
    "save_df(test_df, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('./preprocessed_data/df.train')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
